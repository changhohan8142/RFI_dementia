{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "768b8262-1a62-4e08-a447-519a2c44db29",
   "metadata": {},
   "source": [
    "## GRAD-CAM heatmap and overlay image for manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290508e-fa8e-481a-87b6-162027a7844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Rep Grad-CAM L/R export from saved tensors (manuscript version)\n",
    "# - Assumes the following are ALREADY saved under ./tensors/{MODEL_DESC}_test and ./tensors/{MODEL_DESC}_future:\n",
    "#     * origin_images.pth, saliency_map.pth, test_df.csv, fut_df.csv\n",
    "# - Saves FOV-masked avg heatmaps and overlays to:\n",
    "#     * ./rep_gradcam_lr_manuscript/{MODEL_DESC}/{SET}_{Left|Right}_{heatmap|overlay}.png\n",
    "# - Uses eye_orientation from test_df.csv / fut_df.csv (no meta.json required)\n",
    "\n",
    "import os, random, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "IMG_SIZE = 448\n",
    "SEED     = 123\n",
    "\n",
    "MODEL_DESCS = [\n",
    "    \"retfound_partial_ft_4\",\n",
    "    # \"dinov3_partial_ft_4\",\n",
    "    # \"retfound_dinov2_linear\",\n",
    "    # \"openclip_linear\",\n",
    "    # \"mae_linear\",\n",
    "    # \"dinov2_linear\",\n",
    "    # # ...\n",
    "]\n",
    "\n",
    "TENSORS_ROOT = Path(\"./tensors\")\n",
    "REP_ROOT     = Path(\"./rep_gradcam_lr_manuscript\")  \n",
    "REP_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -----------------------\n",
    "# Utils\n",
    "# -----------------------\n",
    "def _norm_eye_label(x):\n",
    "    if x is None: return None\n",
    "    s = str(x).strip().lower()\n",
    "    if s in [\"r\",\"right\",\"rt\",\"오\",\"오른\",\"오른쪽\",\"1\",\"true\",\"od\",\"o.d\"]:\n",
    "        return \"R\"\n",
    "    if s in [\"l\",\"left\",\"lt\",\"왼\",\"왼쪽\",\"0\",\"false\",\"os\",\"o.s\"]:\n",
    "        return \"L\"\n",
    "    try:\n",
    "        return \"R\" if int(float(s)) == 1 else \"L\"\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def make_fov_mask(h=IMG_SIZE, w=IMG_SIZE):\n",
    "    yy, xx = np.ogrid[:h, :w]\n",
    "    cy, cx = h // 2, w // 2\n",
    "    r = min(h, w) // 2\n",
    "    fov = (yy - cy)**2 + (xx - cx)**2 <= (r**2)\n",
    "    return torch.from_numpy(fov.astype(np.uint8))  # {0,1}\n",
    "\n",
    "def _ensure_hw01(arr_like):\n",
    "    if isinstance(arr_like, torch.Tensor):\n",
    "        x = arr_like.detach().cpu().float()\n",
    "    else:\n",
    "        x = torch.from_numpy(np.asarray(arr_like)).float()\n",
    "    # 정규화 (최소-최대)\n",
    "    mn, mx = float(x.min()), float(x.max())\n",
    "    if mx > mn:\n",
    "        x = (x - mn) / (mx - mn)\n",
    "    else:\n",
    "        x = x * 0.0\n",
    "    return x\n",
    "\n",
    "def _apply_fov_and_renorm(cam_hw_01: torch.Tensor, fov01: torch.Tensor):\n",
    "    cam = (cam_hw_01 * fov01)\n",
    "    inside = cam[fov01 > 0]\n",
    "    if inside.numel() == 0:\n",
    "        return cam_hw_01  \n",
    "    mn, mx = float(inside.min()), float(inside.max())\n",
    "    if mx > mn:\n",
    "        cam = (cam - mn) / (mx - mn + 1e-6)\n",
    "    return cam.clamp_(0, 1)\n",
    "\n",
    "def _to_numpy_img(t3chw: torch.Tensor):\n",
    "    # expects [3,H,W], 0..1\n",
    "    return t3chw.detach().cpu().clamp(0,1).permute(1,2,0).numpy()\n",
    "\n",
    "def _overlay_cam(rgb_hw3, cam_hw01, alpha=0.45, cmap_name=\"jet\"):\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "    cam_rgb = cmap(cam_hw01.detach().cpu().numpy())[..., :3]  # [H,W,3]\n",
    "    out = (1 - alpha) * rgb_hw3 + alpha * cam_rgb\n",
    "    return np.clip(out, 0, 1)\n",
    "\n",
    "def _save_img(array_hw3, fname, out_dir: Path):\n",
    "    out_dir.mkdir(exist_ok=True, parents=True)\n",
    "    plt.imsave(out_dir / fname, array_hw3)\n",
    "    print(f\"[✓] Saved: {out_dir/fname}\")\n",
    "\n",
    "def _save_heatmap(array_hw01, fname, out_dir: Path, cmap=\"jet\"):\n",
    "    out_dir.mkdir(exist_ok=True, parents=True)\n",
    "    plt.imsave(out_dir / fname, array_hw01, cmap=cmap, vmin=0.0, vmax=1.0)\n",
    "    print(f\"[✓] Saved: {out_dir/fname}\")\n",
    "\n",
    "def _avg_heatmap(cam_stack: torch.Tensor, indices, fov01: torch.Tensor):\n",
    "\n",
    "    if not indices: \n",
    "        return None\n",
    "    if cam_stack.dim() == 4:\n",
    "        cams = cam_stack[indices, 0]  # [k,H,W]\n",
    "    else:\n",
    "        cams = cam_stack[indices]     # [k,H,W]\n",
    "    cams01 = torch.stack([_ensure_hw01(c) for c in cams], dim=0)  # [k,H,W]\n",
    "    cams01 = cams01 * fov01  \n",
    "    mean_hw = cams01.mean(dim=0)  # [H,W]\n",
    "    mean_hw = _apply_fov_and_renorm(mean_hw, fov01)\n",
    "    return mean_hw\n",
    "\n",
    "def _random_from(indices, seed=None):\n",
    "    if not indices: return None\n",
    "    rng = random.Random(seed)\n",
    "    return rng.choice(indices)\n",
    "\n",
    "def _load_pack_and_df(src_dir: Path):\n",
    "\n",
    "    origin_p = src_dir / \"origin_images.pth\"\n",
    "    salmap_p = src_dir / \"saliency_map.pth\"\n",
    "\n",
    "    test_csv = src_dir / \"test_df.csv\"\n",
    "    fut_csv  = src_dir / \"fut_df.csv\"\n",
    "    if test_csv.exists():\n",
    "        df = pd.read_csv(test_csv)\n",
    "        set_name = \"TEST\"\n",
    "    elif fut_csv.exists():\n",
    "        df = pd.read_csv(fut_csv)\n",
    "        set_name = \"FUTURE\"\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No test_df.csv or fut_df.csv under {src_dir}\")\n",
    "\n",
    "    assert origin_p.exists() and salmap_p.exists(), f\"Missing tensor files in {src_dir}\"\n",
    "    origin = torch.load(origin_p) \n",
    "    salmap = torch.load(salmap_p)  \n",
    "\n",
    "    n = salmap.size(0)\n",
    "    if len(df) != n:\n",
    "        m = min(len(df), n)\n",
    "        origin = origin[:m]\n",
    "        salmap = salmap[:m]\n",
    "        df = df.iloc[:m].reset_index(drop=True)\n",
    "    return origin, salmap, df, set_name\n",
    "\n",
    "def _indices_by_eye_from_df(df: pd.DataFrame, eye_code: str):\n",
    "    if \"eye_orientation\" not in df.columns:\n",
    "        return list(range(len(df)))  \n",
    "    idxs = []\n",
    "    for i, v in enumerate(df[\"eye_orientation\"].tolist()):\n",
    "        if _norm_eye_label(v) == eye_code:\n",
    "            idxs.append(i)\n",
    "    return idxs\n",
    "\n",
    "def save_heatmap_and_overlay_with_fov(src_dir: Path, model_desc: str, seed=SEED, cmap=\"jet\"):\n",
    "    origin, salmap, df, set_name = _load_pack_and_df(src_dir)\n",
    "\n",
    "    idxs_L = _indices_by_eye_from_df(df, \"L\")\n",
    "    idxs_R = _indices_by_eye_from_df(df, \"R\")\n",
    "\n",
    "    fov01 = make_fov_mask(IMG_SIZE, IMG_SIZE).float()\n",
    "\n",
    "    avg_L = _avg_heatmap(salmap, idxs_L, fov01)\n",
    "    avg_R = _avg_heatmap(salmap, idxs_R, fov01)\n",
    "\n",
    "    rL = _random_from(idxs_L, seed)\n",
    "    rR = _random_from(idxs_R, seed)\n",
    "\n",
    "    out_dir = REP_ROOT / model_desc\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if avg_L is not None:\n",
    "        _save_heatmap(avg_L.detach().cpu().numpy(), f\"{set_name}_Left_heatmap.png\", out_dir, cmap=cmap)\n",
    "        if rL is not None:\n",
    "            rgb = _to_numpy_img(origin[rL])  # [H,W,3], 0..1\n",
    "            ov  = _overlay_cam(rgb, avg_L, alpha=0.45, cmap_name=cmap)\n",
    "            _save_img(ov, f\"{set_name}_Left_overlay.png\", out_dir)\n",
    "\n",
    "    if avg_R is not None:\n",
    "        _save_heatmap(avg_R.detach().cpu().numpy(), f\"{set_name}_Right_heatmap.png\", out_dir, cmap=cmap)\n",
    "        if rR is not None:\n",
    "            rgb = _to_numpy_img(origin[rR])  # [H,W,3], 0..1\n",
    "            ov  = _overlay_cam(rgb, avg_R, alpha=0.45, cmap_name=cmap)\n",
    "            _save_img(ov, f\"{set_name}_Right_overlay.png\", out_dir)\n",
    "\n",
    "# -----------------------\n",
    "# Main\n",
    "# -----------------------\n",
    "def main():\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "    for desc in MODEL_DESCS:\n",
    "        test_dir   = TENSORS_ROOT / f\"{desc}_test\"\n",
    "        future_dir = TENSORS_ROOT / f\"{desc}_future\"\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"[{desc}]\")\n",
    "        if test_dir.exists():\n",
    "            print(f\" - Processing TEST:   {test_dir}\")\n",
    "            save_heatmap_and_overlay_with_fov(test_dir,   model_desc=desc, seed=SEED)\n",
    "        else:\n",
    "            print(\" - TEST dir not found (skip)\")\n",
    "        \n",
    "\n",
    "        if future_dir.exists():\n",
    "            print(f\" - Processing FUTURE: {future_dir}\")\n",
    "            save_heatmap_and_overlay_with_fov(future_dir, model_desc=desc, seed=SEED+1000)\n",
    "        else:\n",
    "            print(\" - FUTURE dir not found (skip)\")\n",
    "            \n",
    "\n",
    "    print(\"\\n✅ Done. Saved FOV-masked heatmaps & overlays to ./rep_gradcam_lr_manuscript/{MODEL_DESC}\")\n",
    "\n",
    "SEED     = 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1890ca27-50a8-4c65-a05f-6f670e8f661d",
   "metadata": {},
   "source": [
    "## individual saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41f8e1-fd80-41b1-872c-20c22ff95132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Single-image Grad-CAM: heatmap (left) + overlay (right)\n",
    "# - MODE: \"detection\" (TEST) or \"prediction\" (FUTURE)\n",
    "# - Loads tensors once per (MODEL_DESC, MODE) and caches for repeated plotting\n",
    "# - Shows figure (1 row x 2 cols) AND saves 2 PNG files (heatmap / overlay)\n",
    "\n",
    "import os, random, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "IMG_SIZE   = 448\n",
    "TENSORS_ROOT = Path(\"./tensors\")\n",
    "OUT_ROOT     = Path(\"./rep_gradcam_lr_manuscript_single\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -----------------------\n",
    "# Cache (for repeated use in notebook)\n",
    "# -----------------------\n",
    "_CACHE = {}  # key: (model_desc, MODE) -> dict(origin, salmap, df, set_name, fov01)\n",
    "\n",
    "# -----------------------\n",
    "# Utils\n",
    "# -----------------------\n",
    "def _norm_eye_label(x):\n",
    "    if x is None: return None\n",
    "    s = str(x).strip().lower()\n",
    "    if s in [\"r\",\"right\",\"rt\",\"오\",\"오른\",\"오른쪽\",\"1\",\"true\",\"od\",\"o.d\"]:\n",
    "        return \"R\"\n",
    "    if s in [\"l\",\"left\",\"lt\",\"왼\",\"왼쪽\",\"0\",\"false\",\"os\",\"o.s\"]:\n",
    "        return \"L\"\n",
    "    try:\n",
    "        return \"R\" if int(float(s)) == 1 else \"L\"\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def _ensure_hw01(arr_like):\n",
    "    x = torch.as_tensor(arr_like, dtype=torch.float32).detach().cpu()\n",
    "    mn, mx = float(x.min()), float(x.max())\n",
    "    if mx > mn:\n",
    "        x = (x - mn) / (mx - mn)\n",
    "    else:\n",
    "        x = x * 0.0\n",
    "    return x\n",
    "\n",
    "def _make_fov_mask(h=IMG_SIZE, w=IMG_SIZE):\n",
    "    yy, xx = np.ogrid[:h, :w]\n",
    "    cy, cx = h // 2, w // 2\n",
    "    r = min(h, w) // 2\n",
    "    fov = (yy - cy)**2 + (xx - cx)**2 <= (r**2)\n",
    "    return torch.from_numpy(fov.astype(np.uint8)).float()  # 0/1 float\n",
    "\n",
    "def _apply_fov_and_renorm(cam_hw01: torch.Tensor, fov01: torch.Tensor):\n",
    "    cam = cam_hw01 * fov01\n",
    "    inside = cam[fov01 > 0]\n",
    "    if inside.numel() == 0:\n",
    "        return cam_hw01\n",
    "    mn, mx = float(inside.min()), float(inside.max())\n",
    "    if mx > mn:\n",
    "        cam = (cam - mn) / (mx - mn + 1e-6)\n",
    "    return cam.clamp_(0, 1)\n",
    "\n",
    "def _overlay_cam(rgb_hw3: np.ndarray, cam_hw01: torch.Tensor, alpha=0.45, cmap_name=\"jet\"):\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "    cam_rgb = cmap(cam_hw01.detach().cpu().numpy())[..., :3]  # [H,W,3]\n",
    "    out = (1 - alpha) * rgb_hw3 + alpha * cam_rgb\n",
    "    return np.clip(out, 0, 1)\n",
    "\n",
    "def _to_numpy_rgb(t3chw: torch.Tensor):\n",
    "    return t3chw.detach().cpu().clamp(0,1).permute(1,2,0).numpy()\n",
    "\n",
    "def _indices_by_eye(df: pd.DataFrame, eye_code: str):\n",
    "    if \"eye_orientation\" not in df.columns:\n",
    "        return list(range(len(df)))\n",
    "    idxs = []\n",
    "    for i, v in enumerate(df[\"eye_orientation\"].tolist()):\n",
    "        if _norm_eye_label(v) == eye_code:\n",
    "            idxs.append(i)\n",
    "    return idxs\n",
    "\n",
    "def _load_pack(model_desc: str, MODE: str):\n",
    "    \"\"\"\n",
    "    MODE: \"detection\" -> _test, uses test_df.csv\n",
    "          \"prediction\" -> _future, uses fut_df.csv\n",
    "    \"\"\"\n",
    "    key = (model_desc, MODE)\n",
    "    if key in _CACHE:\n",
    "        return _CACHE[key]\n",
    "\n",
    "    if MODE not in {\"detection\", \"prediction\"}:\n",
    "        raise ValueError(\"MODE must be 'detection' or 'prediction'\")\n",
    "\n",
    "    sub = f\"{model_desc}_test\" if MODE == \"detection\" else f\"{model_desc}_future\"\n",
    "    src_dir = TENSORS_ROOT / sub\n",
    "\n",
    "    origin_p = src_dir / \"origin_images.pth\"\n",
    "    salmap_p = src_dir / \"saliency_map.pth\"\n",
    "    csv_p    = src_dir / (\"test_df.csv\" if MODE == \"detection\" else \"fut_df.csv\")\n",
    "\n",
    "    if not (origin_p.exists() and salmap_p.exists() and csv_p.exists()):\n",
    "        raise FileNotFoundError(f\"Missing files under: {src_dir}\")\n",
    "\n",
    "    origin = torch.load(origin_p)  # [N,3,H,W], 0..1\n",
    "    salmap = torch.load(salmap_p)  # [N,1,H,W]\n",
    "    df     = pd.read_csv(csv_p)\n",
    "\n",
    "    # length alignment\n",
    "    n = min(len(df), salmap.size(0), origin.size(0))\n",
    "    origin, salmap, df = origin[:n], salmap[:n], df.iloc[:n].reset_index(drop=True)\n",
    "\n",
    "    set_name = \"TEST\" if MODE == \"detection\" else \"FUTURE\"\n",
    "    fov01 = _make_fov_mask(IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "    pack = {\"origin\": origin, \"salmap\": salmap, \"df\": df, \"set_name\": set_name, \"fov01\": fov01, \"src_dir\": src_dir}\n",
    "    _CACHE[key] = pack\n",
    "    return pack\n",
    "\n",
    "# -----------------------\n",
    "# Main render function\n",
    "# -----------------------\n",
    "def render_one(\n",
    "    model_desc: str,\n",
    "    MODE: str = \"detection\",         # \"detection\" or \"prediction\"\n",
    "    EYE: str = \"L\",                   # \"L\" or \"R\"\n",
    "    SEED: int = 0,\n",
    "    idx: int | None = None,           # 특정 index를 지정하고 싶으면 설정, 아니면 시드 기반 랜덤\n",
    "    cmap: str = \"jet\",\n",
    "    alpha: float = 0.45,\n",
    "    out_prefix: str | None = None     # 파일명 접두사를 바꾸고 싶으면 지정\n",
    "):\n",
    "\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "    pack = _load_pack(model_desc, MODE)\n",
    "    origin, salmap, df, set_name, fov01 = pack[\"origin\"], pack[\"salmap\"], pack[\"df\"], pack[\"set_name\"], pack[\"fov01\"]\n",
    "\n",
    "    eye_code = \"L\" if str(EYE).upper().startswith(\"L\") else \"R\"\n",
    "    candidate = _indices_by_eye(df, eye_code)\n",
    "\n",
    "    if len(candidate) == 0:\n",
    "        raise ValueError(f\"No indices for eye={eye_code} in df['eye_orientation'].\")\n",
    "\n",
    "    if idx is None:\n",
    "        rng = random.Random(SEED)\n",
    "        idx = rng.choice(candidate)\n",
    "    else:\n",
    "        if idx not in candidate:\n",
    "            raise ValueError(f\"idx={idx} is not in the {eye_code}-eye subset.\")\n",
    "\n",
    "    # --- pick tensors ---\n",
    "    rgb  = _to_numpy_rgb(origin[idx])                  # [H,W,3], in 0..1\n",
    "    cam0 = salmap[idx, 0]                              # [H,W]\n",
    "    cam01 = _ensure_hw01(cam0)\n",
    "    cam01 = _apply_fov_and_renorm(cam01, fov01)        # FOV 적용 후 재정규화\n",
    "\n",
    "    overlay = _overlay_cam(rgb, cam01, alpha=alpha, cmap_name=cmap)\n",
    "\n",
    "    # --- figure: left=heatmap, right=overlay ---\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5), dpi=160)\n",
    "    ax0, ax1 = axes\n",
    "\n",
    "    im0 = ax0.imshow(cam01.detach().cpu().numpy(), cmap=cmap, vmin=0, vmax=1)\n",
    "    ax0.set_title(\"Heatmap\", fontsize=16)\n",
    "    ax0.axis(\"off\")\n",
    "\n",
    "    ax1.imshow(overlay)\n",
    "    ax1.set_title(\"Overlay\", fontsize=16)\n",
    "    ax1.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- save PNGs ---\n",
    "    out_dir = OUT_ROOT / model_desc\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    base = out_prefix if out_prefix is not None else f\"{set_name}_{eye_code}_idx{idx}_seed{SEED}\"\n",
    "    heatmap_path = out_dir / f\"{base}_heatmap.png\"\n",
    "    overlay_path = out_dir / f\"{base}_overlay.png\"\n",
    "\n",
    "    plt.imsave(heatmap_path, cam01.detach().cpu().numpy(), cmap=cmap, vmin=0, vmax=1)\n",
    "    plt.imsave(overlay_path, overlay)\n",
    "\n",
    "    print(f\"[✓] Saved heatmap : {heatmap_path}\")\n",
    "    print(f\"[✓] Saved overlay : {overlay_path}\")\n",
    "\n",
    "# -----------------------\n",
    "# Usage examples (run repeatedly as you like)\n",
    "# -----------------------\n",
    "# render_one(model_desc=\"retfound_partial_ft_4\", MODE=\"detection\", EYE=\"L\", SEED=123)\n",
    "\n",
    "# render_one(model_desc=\"retfound_partial_ft_4\", MODE=\"prediction\", EYE=\"R\", SEED=7, idx=42)\n",
    "\n",
    "# render_one(model_desc=\"retfound_partial_ft_4\", MODE=\"prediction\", EYE=\"L\", SEED=0, out_prefix=\"figure2_example\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52061179-15b9-4a32-a7f1-3678d8457a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_one(model_desc=\"retfound_partial_ft_4\", MODE=\"prediction\", EYE=\"R\", SEED=52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e10a0c-1781-4bb1-907c-ee61790365f5",
   "metadata": {},
   "source": [
    "## Schematic illustration of the explainability analysis pipeline, including saliency map generation, anatomical segmentation, and computation of regional saliency and relative saliency ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f7f021-cf89-4162-b3ea-7620d134623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with random saliency + FOV outline + padding canvas\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Schematic generator with REAL image & masks (single example, seeded)\n",
    "- Picks one real image (seeded) that has artery/vein/ODC masks present\n",
    "- Uses a procedurally generated (seeded) saliency map (NOT real model saliency)\n",
    "- Saves RGBA PNGs with outside-FOV alpha=0\n",
    "- Adds thin FOV circle outline\n",
    "- Adds small padding around the image to avoid outline clipping\n",
    "\n",
    "Outputs (under ./schematic_out_real):\n",
    "  base_FOV.png\n",
    "  saliency_full_FOV.png\n",
    "  not_optic_disc_not_both_mask.png\n",
    "  not_optic_disc_not_both_saliency.png\n",
    "  veins_mask.png / veins_saliency.png\n",
    "  arteries_mask.png / arteries_saliency.png\n",
    "  both_mask.png / both_saliency.png\n",
    "  optic_disc_mask.png / optic_disc_saliency.png\n",
    "  overlay_image_plus_saliency.png\n",
    "  USED_FILENAME.txt  (which image was used)\n",
    "\"\"\"\n",
    "\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# =========================\n",
    "\n",
    "SEED       = 123\n",
    "H, W       = 448, 448            \n",
    "PADDING    = 12                   \n",
    "OUT_H, OUT_W = H + 2*PADDING, W + 2*PADDING\n",
    "\n",
    "IMAGES_DIR = Path(\"/home/hch/opportunistic/AutoMorph_Data/Results/M0/images\")\n",
    "ARTERY_DIR = Path(\"/home/hch/opportunistic/AutoMorph_Data/Results/M2/artery_vein/artery_binary_process\")\n",
    "VEIN_DIR   = Path(\"/home/hch/opportunistic/AutoMorph_Data/Results/M2/artery_vein/vein_binary_process\")\n",
    "ODC_RAW_DIR= Path(\"/home/hch/opportunistic/AutoMorph_Data/Results/M2/optic_disc_cup/raw\")\n",
    "\n",
    "OUT_DIR    = Path(\"./schematic_out_real\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def circle_fov(h=H, w=W):\n",
    "    yy, xx = np.ogrid[:h, :w]\n",
    "    cy, cx = h//2, w//2\n",
    "    r = min(h, w) // 2\n",
    "    return ((yy - cy)**2 + (xx - cx)**2 <= r*r).astype(np.uint8)\n",
    "\n",
    "def circle_fov_padded(h=OUT_H, w=OUT_W):\n",
    "    yy, xx = np.ogrid[:h, :w]\n",
    "    cy, cx = h//2, w//2\n",
    "    r = min(H, W) // 2\n",
    "    return ((yy - cy)**2 + (xx - cx)**2 <= r*r).astype(np.uint8)\n",
    "\n",
    "def pad_to_canvas(arr, pad=PADDING, fill=0):\n",
    "\n",
    "    if arr.ndim == 2:\n",
    "        out = np.full((arr.shape[0] + 2*pad, arr.shape[1] + 2*pad), fill, arr.dtype)\n",
    "        out[pad:-pad, pad:-pad] = arr\n",
    "    elif arr.ndim == 3:\n",
    "        out = np.full((arr.shape[0] + 2*pad, arr.shape[1] + 2*pad, arr.shape[2]), fill, arr.dtype)\n",
    "        out[pad:-pad, pad:-pad, :] = arr\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported ndim in pad_to_canvas\")\n",
    "    return out\n",
    "\n",
    "def load_image_resize_to_hw(img_path: Path, h=H, w=W):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = img.resize((w, h), resample=Image.BILINEAR)\n",
    "    return np.array(img, dtype=np.uint8)\n",
    "\n",
    "def ensure_bool_mask_from_file(path: Path, h=H, w=W):\n",
    "    \"\"\"\n",
    "    Load mask image file (binary-like), resize to (H, W), return uint8 {0,1}\n",
    "    \"\"\"\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    try:\n",
    "        m = Image.open(path)\n",
    "        m = m.resize((w, h), resample=Image.NEAREST)\n",
    "        arr = np.array(m)\n",
    "        if arr.ndim == 3:\n",
    "            arr = (np.any(arr > 0, axis=-1)).astype(np.uint8)\n",
    "        else:\n",
    "            arr = (arr > 0).astype(np.uint8)\n",
    "        return arr\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def find_file_by_stem(root: Path, stem: str):\n",
    "    for ext in (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\"):\n",
    "        p = root / f\"{stem}{ext}\"\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def find_any_image_by_stem(stem: str):\n",
    "    return find_file_by_stem(IMAGES_DIR, stem)\n",
    "\n",
    "def load_optic_disc_union_by_stem(stem: str, h=H, w=W):\n",
    "    p = find_file_by_stem(ODC_RAW_DIR, stem)\n",
    "    if p is None:\n",
    "        return None\n",
    "    try:\n",
    "        img = Image.open(p).convert(\"RGB\").resize((w, h), resample=Image.NEAREST)\n",
    "        arr = np.array(img)\n",
    "        r = arr[..., 0]; b = arr[..., 2]\n",
    "        rb = ((r > 0) | (b > 0)).astype(np.uint8)\n",
    "        return rb\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def to_rgba(img_rgb, fov_mask):\n",
    "    \"\"\"\n",
    "    img_rgb: uint8 [H,W,3]; fov_mask: uint8/bool [H,W] (1=inside)\n",
    "    Returns RGBA with outside-FOV alpha=0\n",
    "    \"\"\"\n",
    "    h, w, _ = img_rgb.shape\n",
    "    rgba = np.dstack([img_rgb, np.full((h,w), 255, np.uint8)])\n",
    "    rgba[..., 3] = (fov_mask.astype(np.uint8) * 255)\n",
    "    return rgba\n",
    "\n",
    "def save_rgba(arr_rgba, path: Path):\n",
    "    Image.fromarray(arr_rgba, mode=\"RGBA\").save(str(path))\n",
    "\n",
    "def add_fov_outline(rgba_img: np.ndarray, fov_mask: np.ndarray,\n",
    "                    color=(0, 0, 0), thickness=2, antialias=False) -> np.ndarray:\n",
    "\n",
    "    mask255 = (fov_mask.astype(np.uint8) * 255)\n",
    "    mask255 = np.ascontiguousarray(mask255)\n",
    "\n",
    "    contours, _ = cv2.findContours(mask255, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    out = np.ascontiguousarray(rgba_img.copy())\n",
    "    rgb = np.ascontiguousarray(out[..., :3].copy())\n",
    "    line_type = cv2.LINE_AA if antialias else cv2.LINE_8\n",
    "    for cnt in contours:\n",
    "        #cv2.drawContours(rgb, [cnt], -1, color, thickness=thickness, lineType=line_type)\n",
    "        cv2.drawContours(rgb, [cnt], -1, color, thickness=1, lineType=cv2.LINE_AA)\n",
    "    out[..., :3] = rgb\n",
    "\n",
    "    a = np.ascontiguousarray(out[..., 3].copy())\n",
    "    for cnt in contours:\n",
    "        cv2.drawContours(a, [cnt], -1, 255, thickness=thickness, lineType=line_type)\n",
    "        #cv2.drawContours(rgb, [cnt], -1, color, thickness=1, lineType=cv2.LINE_AA)\n",
    "    out[..., 3] = a\n",
    "    return out\n",
    "# --------------------------------------\n",
    "\n",
    "def smooth_random_saliency(h=H, w=W, octaves=5, base_sigma=7.0):\n",
    "    s = np.random.rand(h, w).astype(np.float32)\n",
    "    for i in range(octaves):\n",
    "        sigma = base_sigma * (i + 1)\n",
    "        s = cv2.GaussianBlur(s, (0, 0), sigmaX=sigma, sigmaY=sigma)\n",
    "    s -= s.min()\n",
    "    s /= (s.max() + 1e-6)\n",
    "    return s\n",
    "\n",
    "def colorize_saliency(sal, cmap=\"jet\"):\n",
    "    \"\"\"\n",
    "    sal: [H,W] in [0,1]\n",
    "    return: uint8 RGB [H,W,3]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        m = plt.colormaps[cmap]   # matplotlib>=3.8\n",
    "    except Exception:\n",
    "        m = cm.get_cmap(cmap)     # fallback\n",
    "    rgb = m(sal)[..., :3]\n",
    "    return (rgb * 255).astype(np.uint8)\n",
    "\n",
    "def render_binary_mask(mask01, fov, color_one=(211, 211, 211), color_zero=(255,255,255)):\n",
    "\n",
    "    mask01 = (mask01.astype(np.uint8) & fov.astype(np.uint8))\n",
    "    h, w = mask01.shape\n",
    "    out = np.zeros((h, w, 4), np.uint8)\n",
    "    out[..., :3] = np.array(color_zero, np.uint8)\n",
    "    out[..., 3]  = (fov * 255).astype(np.uint8)\n",
    "    idx = mask01.astype(bool)\n",
    "    out[idx, 0] = color_one[0]\n",
    "    out[idx, 1] = color_one[1]\n",
    "    out[idx, 2] = color_one[2]\n",
    "    return out\n",
    "\n",
    "def render_saliency_in_region(sal_rgb, region01, fov):\n",
    "\n",
    "    h, w, _ = sal_rgb.shape\n",
    "    out = np.dstack([sal_rgb.copy(), np.zeros((h,w), np.uint8)])\n",
    "    visible = (region01.astype(np.uint8) & fov.astype(np.uint8))\n",
    "    out[..., 3] = (visible * 255).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "def logical_or(*arrs):\n",
    "    out = None\n",
    "    for a in arrs:\n",
    "        if a is None:\n",
    "            continue\n",
    "        out = a if out is None else np.clip(out | a, 0, 1).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# Candidate selection\n",
    "# =========================\n",
    "def collect_stems(root: Path):\n",
    "    stems = set()\n",
    "    for p in root.glob(\"*\"):\n",
    "        if p.is_file():\n",
    "            stems.add(p.stem)\n",
    "    return stems\n",
    "\n",
    "def pick_one_filename_with_all_masks(seed=SEED):\n",
    "\n",
    "    art_stems = collect_stems(ARTERY_DIR)\n",
    "    vein_stems= collect_stems(VEIN_DIR)\n",
    "    odc_stems = collect_stems(ODC_RAW_DIR)\n",
    "\n",
    "    common = list(art_stems & vein_stems & odc_stems)\n",
    "\n",
    "    if not common:\n",
    "        common = list(art_stems & vein_stems)\n",
    "\n",
    "    valid = []\n",
    "    for s in common:\n",
    "        imp = find_any_image_by_stem(s)\n",
    "        if imp is not None:\n",
    "            valid.append((s, imp))\n",
    "    if not valid:\n",
    "        raise FileNotFoundError(\"No common stem with image + artery/vein (+/- ODC). Check paths.\")\n",
    "    rng = random.Random(seed)\n",
    "    stem, imgp = rng.choice(valid)\n",
    "    return stem, imgp\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main(seed=SEED):\n",
    "    set_seed(seed)\n",
    "\n",
    "\n",
    "    stem, img_path = pick_one_filename_with_all_masks(seed)\n",
    "    with open(OUT_DIR/\"USED_FILENAME.txt\", \"w\") as f:\n",
    "        f.write(f\"{stem}\\n{img_path}\\n\")\n",
    "\n",
    "\n",
    "    img = load_image_resize_to_hw(img_path, H, W)\n",
    "\n",
    "\n",
    "    art_p = find_file_by_stem(ARTERY_DIR, stem)\n",
    "    vein_p= find_file_by_stem(VEIN_DIR,   stem)\n",
    "    odc   = load_optic_disc_union_by_stem(stem, H, W)   # optic disc ∪ cup\n",
    "\n",
    "    arteries = ensure_bool_mask_from_file(art_p, H, W) if art_p else None\n",
    "    veins    = ensure_bool_mask_from_file(vein_p, H, W) if vein_p else None\n",
    "    both     = None\n",
    "    if arteries is not None and veins is not None:\n",
    "        both = np.clip(arteries | veins, 0, 1).astype(np.uint8)\n",
    "\n",
    "\n",
    "    fov_small = circle_fov(H, W)\n",
    "\n",
    "    fov_big   = circle_fov_padded(OUT_H, OUT_W)\n",
    "\n",
    "\n",
    "    img_rgba = to_rgba(img, fov_small)                 # (H,W,4)\n",
    "    img_rgba = pad_to_canvas(img_rgba, PADDING, fill=0)# (OUT_H,OUT_W,4)\n",
    "    img_rgba = add_fov_outline(img_rgba, fov_big, color=(0,0,0), thickness=1)\n",
    "    Image.fromarray(img_rgba, mode=\"RGBA\").save(str(OUT_DIR / \"base_FOV.png\"))\n",
    "\n",
    "\n",
    "    sal = smooth_random_saliency(H, W, octaves=3)\n",
    "    sal_rgb = colorize_saliency(sal, cmap=\"jet\")       # (H,W,3)\n",
    "    sal_rgba_full = to_rgba(sal_rgb, fov_small)        # (H,W,4)\n",
    "    sal_rgba_full = pad_to_canvas(sal_rgba_full, PADDING, fill=0)\n",
    "    sal_rgba_full = add_fov_outline(sal_rgba_full, fov_big, color=(0,0,0), thickness=1)\n",
    "    Image.fromarray(sal_rgba_full, mode=\"RGBA\").save(str(OUT_DIR / \"saliency_full_FOV.png\"))\n",
    "\n",
    "\n",
    "    if both is None:\n",
    "        not_both_f = (fov_small & 1).astype(np.uint8)   \n",
    "    else:\n",
    "        not_both_f = (fov_small & (1 - both)).astype(np.uint8)\n",
    "\n",
    "    if odc is None:\n",
    "        not_od_f = (fov_small & 1).astype(np.uint8)     \n",
    "    else:\n",
    "        not_od_f = (fov_small & (1 - odc)).astype(np.uint8)\n",
    "\n",
    "    not_od_not_both = (fov_small & (1 - logical_or(both if both is not None else np.zeros_like(fov_small),\n",
    "                                                   odc  if odc  is not None else np.zeros_like(fov_small)))).astype(np.uint8)\n",
    "\n",
    "\n",
    "    def do_region(name, mask01):\n",
    "        mask_rgba = render_binary_mask(mask01, fov_small, color_one=(211, 211, 211), color_zero=(255,255,255))\n",
    "        mask_rgba = pad_to_canvas(mask_rgba, PADDING, fill=0)\n",
    "        mask_rgba = add_fov_outline(mask_rgba, fov_big, color=(0,0,0), thickness=1)\n",
    "        Image.fromarray(mask_rgba, mode=\"RGBA\").save(str(OUT_DIR / f\"{name}_mask.png\"))\n",
    "\n",
    "        sal_in = render_saliency_in_region(sal_rgb, mask01, fov_small)\n",
    "        sal_in = pad_to_canvas(sal_in, PADDING, fill=0)\n",
    "        sal_in = add_fov_outline(sal_in, fov_big, color=(0,0,0), thickness=1)\n",
    "        Image.fromarray(sal_in, mode=\"RGBA\").save(str(OUT_DIR / f\"{name}_saliency.png\"))\n",
    "\n",
    "    # (3)(4) not_optic_disc_not_both\n",
    "    do_region(\"not_optic_disc_not_both\", not_od_not_both)\n",
    "\n",
    "    # (5) veins, arteries, both, optic_disc 각각 반복\n",
    "    if veins is not None:\n",
    "        do_region(\"veins\", (veins & fov_small).astype(np.uint8))\n",
    "    if arteries is not None:\n",
    "        do_region(\"arteries\", (arteries & fov_small).astype(np.uint8))\n",
    "    if both is not None:\n",
    "        do_region(\"both\", (both & fov_small).astype(np.uint8))\n",
    "    if odc is not None:\n",
    "        do_region(\"optic_disc\", (odc & fov_small).astype(np.uint8))\n",
    "\n",
    "\n",
    "    overlay = (0.55*img.astype(np.float32) + 0.45*sal_rgb.astype(np.float32)).clip(0,255).astype(np.uint8)\n",
    "    overlay_rgba = to_rgba(overlay, fov_small)\n",
    "    overlay_rgba = pad_to_canvas(overlay_rgba, PADDING, fill=0)\n",
    "    overlay_rgba = add_fov_outline(overlay_rgba, fov_big, color=(0,0,0), thickness=1)\n",
    "    Image.fromarray(overlay_rgba, mode=\"RGBA\").save(str(OUT_DIR / \"overlay_image_plus_saliency.png\"))\n",
    "\n",
    "    print(\"\\n[Saved files in]\", OUT_DIR.resolve())\n",
    "    for p in sorted(OUT_DIR.glob(\"*.png\")):\n",
    "        print(\"-\", p.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c580b05-2712-4341-98c9-4c1d6cb7a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d084e5f4-5569-4a98-8ab2-7bf00c27ceba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automorph",
   "language": "python",
   "name": "automorph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
