{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aad2e89-fda4-41f3-bcbe-22cb132cd6e9",
   "metadata": {},
   "source": [
    "## AUROC, C-index bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f0adff-c8c0-43c1-8a2e-1bb077737ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Unified bootstrap across all models ===\n",
    "\n",
    "\n",
    "import os, sys, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import statsmodels.api as sm\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "# =========================\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "WORK_DIR  = \"/home/hch/dementia\"\n",
    "INFER_DIR = os.path.join(WORK_DIR, \"infer_out\")\n",
    "OUT_SUMMARY = os.path.join(INFER_DIR, \"summary_metrics_pretty.csv\")\n",
    "os.chdir(WORK_DIR)\n",
    "\n",
    "N_BOOT = 2000          # 필요시 2000으로\n",
    "SEED_AUC = 1234\n",
    "SEED_CIDX = 5678\n",
    "\n",
    "# =========================\n",
    "def fmt_p(p):\n",
    "    if pd.isna(p): return np.nan\n",
    "    try:\n",
    "        return \"<0.001\" if float(p) < 0.001 else float(f\"{float(p):.3f}\")\n",
    "    except Exception:\n",
    "        return p\n",
    "\n",
    "def safe_auc(y, s):\n",
    "    try:\n",
    "        if len(y) > 0 and pd.Series(y).nunique() == 2:\n",
    "            return float(roc_auc_score(y, s))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.nan\n",
    "\n",
    "def cindex_from_risk(times, risk, events):\n",
    "    try:\n",
    "        return concordance_index(event_times=np.asarray(times),\n",
    "                                 predicted_scores=-np.asarray(risk),\n",
    "                                 event_observed=np.asarray(events))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def progress_print(i, n, tag):\n",
    "    step = i + 1\n",
    "    if step == n or step % max(1, n // 20) == 0:  # 5% 간격\n",
    "        pct = int(round(step / n * 100))\n",
    "        sys.stdout.write(f\"\\r[{tag}] {step}/{n} ({pct}%)\")\n",
    "        sys.stdout.flush()\n",
    "    if step == n:\n",
    "        sys.stdout.write(\"\\n\")\n",
    "\n",
    "# =========================\n",
    "det_all  = pd.read_csv(\"dementia_detection.csv\", low_memory=False)\n",
    "det_test = det_all[det_all[\"test\"] == True].reset_index(drop=True)\n",
    "\n",
    "surv_all = pd.read_csv(\"dementia_prediction.csv\", low_memory=False).reset_index(drop=True)\n",
    "\n",
    "def add_common_covs(df):\n",
    "    out = df.copy()\n",
    "\n",
    "    if \"STDY_DT\" in out.columns:\n",
    "        out[\"STDY_DT\"] = pd.to_datetime(out[\"STDY_DT\"], errors=\"coerce\")\n",
    "\n",
    "    if \"SEXINT\" not in out.columns:\n",
    "        if \"SEX\" in out.columns:\n",
    "            out[\"SEXINT\"] = (out[\"SEX\"] == \"M\").astype(int)\n",
    "        else:\n",
    "            out[\"SEXINT\"] = np.nan\n",
    "\n",
    "    if \"EXERCISE_STATUS_bin\" not in out.columns:\n",
    "        if \"EXERCISE_STATUS\" in out.columns:\n",
    "            ex = pd.to_numeric(out[\"EXERCISE_STATUS\"], errors=\"coerce\")\n",
    "            out[\"EXERCISE_STATUS_bin\"] = np.where(ex >= 2, 1, np.where(ex <= 1, 0, np.nan))\n",
    "        else:\n",
    "            out[\"EXERCISE_STATUS_bin\"] = np.nan\n",
    "\n",
    "    for c in [\"STDY_AGE\", \"cholesterol_updated\", \"sbp\", \"bmi\", \"days_diff\"]:\n",
    "        if c in out.columns:\n",
    "            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "        else:\n",
    "            out[c] = np.nan\n",
    "    return out\n",
    "\n",
    "det_test = add_common_covs(det_test)\n",
    "surv_all = add_common_covs(surv_all)\n",
    "\n",
    "def recompute_survival_frame(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    fut = frame.copy()\n",
    "    fut[\"event\"] = (fut[\"days_diff\"] >= 730).astype(int)\n",
    "    fut = fut[fut[\"event\"].eq(1) | fut[\"days_diff\"].isna()].copy()\n",
    "    ref = pd.Timestamp(\"2019-01-01\")\n",
    "    fut[\"obs_time\"] = np.where(\n",
    "        fut.event == 1,\n",
    "        (fut[\"days_diff\"] - 730).clip(lower=0),\n",
    "        (ref - fut[\"STDY_DT\"]).dt.days - 730\n",
    "    )\n",
    "    fut.loc[fut.obs_time > 3650, \"obs_time\"] = 3650\n",
    "    fut.loc[(fut.event == 1) & (fut.obs_time == 3650), \"event\"] = 0\n",
    "    return fut\n",
    "\n",
    "surv_all = recompute_survival_frame(surv_all)\n",
    "\n",
    "def calc_caide_napoe(frame: pd.DataFrame) -> pd.Series:\n",
    "    x = frame.copy()\n",
    "    for col in [\"STDY_AGE\",\"SEXINT\",\"sbp\",\"bmi\",\"cholesterol_updated\",\"EXERCISE_STATUS\"]:\n",
    "        if col in x.columns:\n",
    "            x[col] = pd.to_numeric(x[col], errors=\"coerce\")\n",
    "        else:\n",
    "            x[col] = np.nan\n",
    "    age = x[\"STDY_AGE\"]\n",
    "    age_pts = np.select([age < 47, (47 <= age) & (age <= 53), age > 53], [0,3,4], default=np.nan)\n",
    "    sex_pts = np.where(x[\"SEXINT\"]==1, 1, 0)\n",
    "    edu_pts = np.zeros(len(x), dtype=float)  # 교육 변수 없으면 0\n",
    "    sbp_pts = np.where(x[\"sbp\"] >= 140, 2, 0)\n",
    "    bmi_pts = np.where(x[\"bmi\"] >= 30, 2, 0)\n",
    "    chol_mmol = x[\"cholesterol_updated\"] * 0.02586\n",
    "    chol_pts  = np.where(chol_mmol >= 6.5, 2, 0)\n",
    "    ex = x[\"EXERCISE_STATUS\"]\n",
    "    pa_pts = np.where(ex >= 2, 0, 1)\n",
    "    score = age_pts + sex_pts + edu_pts + sbp_pts + bmi_pts + chol_pts + pa_pts\n",
    "    return pd.Series(score, index=frame.index, name=\"CAIDE_noAPOE\")\n",
    "\n",
    "def caide_valid_mask(frame: pd.DataFrame) -> pd.Series:\n",
    "    req = [\"STDY_AGE\",\"SEXINT\",\"sbp\",\"bmi\",\"cholesterol_updated\",'EXERCISE_STATUS']\n",
    "    req = [\"STDY_AGE\"]\n",
    "    return frame[req].notna().all(axis=1)\n",
    "\n",
    "det_CAIDE = calc_caide_napoe(det_test)\n",
    "det_CAIDE_mask = caide_valid_mask(det_test)\n",
    "\n",
    "surv_CAIDE = calc_caide_napoe(surv_all)\n",
    "surv_CAIDE_mask = caide_valid_mask(surv_all) & surv_all[\"obs_time\"].notna() & surv_all[\"event\"].notna()\n",
    "\n",
    "COVARS = [\"STDY_AGE\",\"SEXINT\",\"cholesterol_updated\",\"sbp\",\"bmi\",\"EXERCISE_STATUS_bin\"]\n",
    "X_test_base = det_test[COVARS]\n",
    "test_cov_mask = X_test_base.notna().all(axis=1)\n",
    "\n",
    "X_fut_base = surv_all[COVARS]\n",
    "fut_cov_mask = X_fut_base.notna().all(axis=1)\n",
    "fut_obs_time = surv_all[\"obs_time\"].to_numpy()\n",
    "fut_event    = surv_all[\"event\"].to_numpy()\n",
    "\n",
    "# =========================\n",
    "model_dirs = sorted([p for p in Path(INFER_DIR).glob(\"*\") if p.is_dir() and (p/\"test_preds.csv\").exists()])\n",
    "\n",
    "# test: 각 모델의 (idx, label, pred)\n",
    "test_series = {}   # model_desc -> Series(pred, index=idx)\n",
    "test_labels = {}   # model_desc -> Series(label, index=idx)\n",
    "\n",
    "# future: 각 모델의 (idx, pred)\n",
    "fut_series  = {}   # model_desc -> Series(pred, index=idx)\n",
    "\n",
    "for mdir in model_dirs:\n",
    "    desc = mdir.name\n",
    "\n",
    "    # ---- Test\n",
    "    test_csv = mdir / \"test_preds.csv\"\n",
    "    try:\n",
    "        tp = pd.read_csv(\n",
    "            test_csv,\n",
    "            usecols=[\"idx\",\"label\",\"pred\"],\n",
    "            dtype={\"idx\": np.int64, \"label\": np.float64, \"pred\": np.float64}\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] skip {desc} (bad test_preds.csv): {e}\")\n",
    "        continue\n",
    "\n",
    "    s_pred = pd.Series(tp[\"pred\"].to_numpy(dtype=float), index=tp[\"idx\"].to_numpy(dtype=np.int64), name=desc)\n",
    "    s_lab  = pd.Series(tp[\"label\"].to_numpy(dtype=float), index=tp[\"idx\"].to_numpy(dtype=np.int64), name=\"label\")\n",
    "    test_series[desc] = s_pred\n",
    "    test_labels[desc] = s_lab\n",
    "\n",
    "    # ---- Future (optional)\n",
    "    fut_csv = mdir / \"prediction_preds.csv\"\n",
    "    if fut_csv.exists():\n",
    "        try:\n",
    "            fp = pd.read_csv(\n",
    "                fut_csv,\n",
    "                usecols=[\"idx\",\"pred\"],\n",
    "                dtype={\"idx\": np.int64, \"pred\": np.float64}\n",
    "            )\n",
    "            fut_series[desc] = pd.Series(fp[\"pred\"].to_numpy(dtype=float),\n",
    "                                         index=fp[\"idx\"].to_numpy(dtype=np.int64),\n",
    "                                         name=desc)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] skip future for {desc}: {e}\")\n",
    "\n",
    "# =========================\n",
    "all_test_idx_sets = [s.index for s in test_series.values()]\n",
    "if len(all_test_idx_sets) == 0:\n",
    "    raise RuntimeError(\"No valid test predictions found.\")\n",
    "\n",
    "common_test_idx = set(all_test_idx_sets[0])\n",
    "for idx_set in all_test_idx_sets[1:]:\n",
    "    common_test_idx &= set(idx_set)\n",
    "\n",
    "first_model_for_label = next(iter(test_labels))\n",
    "labels_first = test_labels[first_model_for_label]\n",
    "\n",
    "common_test_idx &= set(np.where(det_CAIDE_mask.to_numpy())[0])\n",
    "common_test_idx &= set(labels_first.index[np.isfinite(labels_first.values)])\n",
    "common_test_idx = np.array(sorted(common_test_idx), dtype=np.int64)\n",
    "\n",
    "all_fut_idx_sets = [s.index for s in fut_series.values()] if len(fut_series) > 0 else []\n",
    "common_fut_idx = None\n",
    "if len(all_fut_idx_sets) > 0:\n",
    "    common_fut_idx = set(all_fut_idx_sets[0])\n",
    "    for idx_set in all_fut_idx_sets[1:]:\n",
    "        common_fut_idx &= set(idx_set)\n",
    "    common_fut_idx &= set(np.where(surv_CAIDE_mask.to_numpy())[0])\n",
    "    fin_mask = np.isfinite(fut_obs_time) & np.isfinite(fut_event)\n",
    "    common_fut_idx &= set(np.where(fin_mask)[0])\n",
    "    common_fut_idx = np.array(sorted(common_fut_idx), dtype=np.int64)\n",
    "\n",
    "# =========================\n",
    "model_names = sorted(test_series.keys())\n",
    "\n",
    "y_test_all   = labels_first.reindex(common_test_idx).to_numpy(dtype=float)\n",
    "s_caide_test = det_CAIDE.reindex(common_test_idx).to_numpy(dtype=float)\n",
    "\n",
    "S_test = np.zeros((len(common_test_idx), len(model_names)), dtype=float)\n",
    "for j, m in enumerate(model_names):\n",
    "    S_test[:, j] = test_series[m].reindex(common_test_idx).to_numpy(dtype=float)\n",
    "\n",
    "have_future = common_fut_idx is not None and len(common_fut_idx) > 1\n",
    "if have_future:\n",
    "    t_fut_all = fut_obs_time[common_fut_idx]\n",
    "    e_fut_all = fut_event[common_fut_idx]\n",
    "    r_caide_f = surv_CAIDE.reindex(common_fut_idx).to_numpy(dtype=float)\n",
    "\n",
    "    R_fut = np.zeros((len(common_fut_idx), len(model_names)), dtype=float)\n",
    "    for j, m in enumerate(model_names):\n",
    "        if m in fut_series:\n",
    "            R_fut[:, j] = fut_series[m].reindex(common_fut_idx).to_numpy(dtype=float)\n",
    "        else:\n",
    "            R_fut[:, j] = np.nan\n",
    "\n",
    "# =========================\n",
    "auc_caide = safe_auc(y_test_all, s_caide_test)\n",
    "auc_models = [safe_auc(y_test_all, S_test[:, j]) for j in range(len(model_names))]\n",
    "\n",
    "cidx_caide = np.nan\n",
    "cidx_models = [np.nan] * len(model_names)\n",
    "if have_future:\n",
    "    cidx_caide = cindex_from_risk(t_fut_all, r_caide_f, e_fut_all)\n",
    "    for j in range(len(model_names)):\n",
    "        cidx_models[j] = cindex_from_risk(t_fut_all, R_fut[:, j], e_fut_all)\n",
    "\n",
    "# =========================\n",
    "rng_auc  = np.random.default_rng(SEED_AUC)\n",
    "rng_cidx = np.random.default_rng(SEED_CIDX)\n",
    "\n",
    "auc_boot_mat   = []  \n",
    "auc_boot_caide = []  \n",
    "diffs_auc_mat  = []  \n",
    "\n",
    "if pd.Series(y_test_all).nunique() == 2 and len(y_test_all) >= 2:\n",
    "    n = len(y_test_all)\n",
    "    for b in range(N_BOOT):\n",
    "        idx = rng_auc.integers(0, n, size=n)\n",
    "        yb = y_test_all[idx]\n",
    "        progress_print(b, N_BOOT, \"AUC  boot\")\n",
    "        if pd.Series(yb).nunique() < 2:\n",
    "            continue\n",
    "        s_cai_b = s_caide_test[idx]\n",
    "\n",
    "        # CAIDE AUROC\n",
    "        try:\n",
    "            auc_cai_b = roc_auc_score(yb, s_cai_b)\n",
    "        except Exception:\n",
    "            auc_cai_b = np.nan\n",
    "\n",
    "        aucs_b = np.full(len(model_names), np.nan, dtype=float)\n",
    "        diffs_b = np.full(len(model_names), np.nan, dtype=float)\n",
    "        for j in range(len(model_names)):\n",
    "            s_m_b = S_test[idx, j]\n",
    "            try:\n",
    "                auc_m_b = roc_auc_score(yb, s_m_b)\n",
    "                aucs_b[j] = auc_m_b\n",
    "                diffs_b[j] = auc_m_b - auc_cai_b\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        auc_boot_mat.append(aucs_b)\n",
    "        auc_boot_caide.append(auc_cai_b)\n",
    "        diffs_auc_mat.append(diffs_b)\n",
    "\n",
    "if len(auc_boot_mat) > 0:\n",
    "    auc_boot_mat   = np.vstack(auc_boot_mat)                      # (B_eff, n_models)\n",
    "    auc_boot_caide = np.asarray(auc_boot_caide, dtype=float)      # (B_eff,)\n",
    "    diffs_auc_mat  = np.vstack(diffs_auc_mat)                     # (B_eff, n_models)\n",
    "    auc_lo = np.nanpercentile(auc_boot_mat, 2.5, axis=0)\n",
    "    auc_hi = np.nanpercentile(auc_boot_mat, 97.5, axis=0)\n",
    "    # CAIDE AUROC 95% CI\n",
    "    auc_caide_lo, auc_caide_hi = np.nanpercentile(auc_boot_caide, [2.5, 97.5])\n",
    "    # ΔAUROC 95% CI\n",
    "    diff_auc_means = np.nanmean(diffs_auc_mat, axis=0)\n",
    "    diff_auc_lo    = np.nanpercentile(diffs_auc_mat, 2.5, axis=0)\n",
    "    diff_auc_hi    = np.nanpercentile(diffs_auc_mat, 97.5, axis=0)\n",
    "else:\n",
    "    auc_lo = auc_hi = diff_auc_means = diff_auc_lo = diff_auc_hi = None\n",
    "    auc_caide_lo = auc_caide_hi = np.nan\n",
    "\n",
    "cidx_boot_mat   = []\n",
    "cidx_boot_caide = []\n",
    "diffs_cidx_mat  = []\n",
    "\n",
    "if have_future and len(t_fut_all) >= 2:\n",
    "    n = len(t_fut_all)\n",
    "    for b in range(N_BOOT):\n",
    "        idx = rng_cidx.integers(0, n, size=n)\n",
    "        tb, eb = t_fut_all[idx], e_fut_all[idx]\n",
    "        r_cai_b = r_caide_f[idx]\n",
    "        progress_print(b, N_BOOT, \"Cidx boot\")\n",
    "        try:\n",
    "            c_cai_b = cindex_from_risk(tb, r_cai_b, eb)\n",
    "        except Exception:\n",
    "            c_cai_b = np.nan\n",
    "\n",
    "        cidxs_b = np.full(len(model_names), np.nan, dtype=float)\n",
    "        diffs_b = np.full(len(model_names), np.nan, dtype=float)\n",
    "        for j in range(len(model_names)):\n",
    "            r_m_b = R_fut[idx, j]\n",
    "            try:\n",
    "                c_m_b = cindex_from_risk(tb, r_m_b, eb)\n",
    "                cidxs_b[j] = c_m_b\n",
    "                diffs_b[j] = c_m_b - c_cai_b\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        cidx_boot_mat.append(cidxs_b)\n",
    "        cidx_boot_caide.append(c_cai_b)\n",
    "        diffs_cidx_mat.append(diffs_b)\n",
    "\n",
    "if len(cidx_boot_mat) > 0:\n",
    "    cidx_boot_mat   = np.vstack(cidx_boot_mat)                    # (B_eff, n_models)\n",
    "    cidx_boot_caide = np.asarray(cidx_boot_caide, dtype=float)    # (B_eff,)\n",
    "    diffs_cidx_mat  = np.vstack(diffs_cidx_mat)                   # (B_eff, n_models)\n",
    "    cidx_lo = np.nanpercentile(cidx_boot_mat, 2.5, axis=0)\n",
    "    cidx_hi = np.nanpercentile(cidx_boot_mat, 97.5, axis=0)\n",
    "    # CAIDE C-index 95% CI\n",
    "    cidx_caide_lo, cidx_caide_hi = np.nanpercentile(cidx_boot_caide, [2.5, 97.5])\n",
    "    # ΔC-index 95% CI\n",
    "    diff_cidx_means = np.nanmean(diffs_cidx_mat, axis=0)\n",
    "    diff_cidx_lo    = np.nanpercentile(diffs_cidx_mat, 2.5, axis=0)\n",
    "    diff_cidx_hi    = np.nanpercentile(diffs_cidx_mat, 97.5, axis=0)\n",
    "else:\n",
    "    cidx_lo = cidx_hi = diff_cidx_means = diff_cidx_lo = diff_cidx_hi = None\n",
    "    cidx_caide_lo = cidx_caide_hi = np.nan\n",
    "\n",
    "# =========================\n",
    "print(\"\\n=== CAIDE (Common cohort) ===\")\n",
    "if not pd.isna(auc_caide):\n",
    "    print(f\"AUROC (CAIDE): {auc_caide:.3f}\", end=\"\")\n",
    "    if not np.isnan(auc_caide_lo):\n",
    "        print(f\"  | 95% CI [{auc_caide_lo:.3f}, {auc_caide_hi:.3f}]\")\n",
    "    else:\n",
    "        print()\n",
    "else:\n",
    "    print(\"AUROC (CAIDE): NA\")\n",
    "if have_future and not pd.isna(cidx_caide):\n",
    "    line = f\"C-index (CAIDE): {cidx_caide:.3f}\"\n",
    "    if not np.isnan(cidx_caide_lo):\n",
    "        line += f\"  | 95% CI [{cidx_caide_lo:.3f}, {cidx_caide_hi:.3f}]\"\n",
    "    print(line)\n",
    "\n",
    "for j, m in enumerate(model_names):\n",
    "    print(f\"\\n=== {m} (Common cohort) ===\")\n",
    "    # AUROC & 95% CI\n",
    "    auc_m = auc_models[j]\n",
    "    if not pd.isna(auc_m):\n",
    "        line = f\"AUROC (Model): {auc_m:.3f}\"\n",
    "        if isinstance(auc_lo, np.ndarray) and not pd.isna(auc_lo[j]):\n",
    "            line += f\"  | 95% CI [{auc_lo[j]:.3f}, {auc_hi[j]:.3f}]\"\n",
    "        print(line)\n",
    "    else:\n",
    "        print(\"AUROC (Model): NA\")\n",
    "    # ΔAUROC 95% CI\n",
    "    if isinstance(diff_auc_means, np.ndarray) and not any(pd.isna([diff_auc_means[j], diff_auc_lo[j], diff_auc_hi[j]])):\n",
    "        print(f\"ΔAUROC (Model − CAIDE) 95% CI: {diff_auc_means[j]:.4f} [{diff_auc_lo[j]:.4f}, {diff_auc_hi[j]:.4f}]\")\n",
    "    else:\n",
    "        print(\"ΔAUROC 95% CI: NA\")\n",
    "\n",
    "    if have_future:\n",
    "        # C-index & 95% CI\n",
    "        c_m = cidx_models[j]\n",
    "        if not pd.isna(c_m):\n",
    "            line = f\"C-index (Model): {c_m:.3f}\"\n",
    "            if isinstance(cidx_lo, np.ndarray) and not pd.isna(cidx_lo[j]):\n",
    "                line += f\"  | 95% CI [{cidx_lo[j]:.3f}, {cidx_hi[j]:.3f}]\"\n",
    "            print(line)\n",
    "        else:\n",
    "            print(\"C-index (Model): NA\")\n",
    "        # ΔC-index 95% CI\n",
    "        if isinstance(diff_cidx_means, np.ndarray) and not any(pd.isna([diff_cidx_means[j], diff_cidx_lo[j], diff_cidx_hi[j]])):\n",
    "            print(f\"ΔC-index (Model − CAIDE) 95% CI: {diff_cidx_means[j]:.4f} [{diff_cidx_lo[j]:.4f}, {diff_cidx_hi[j]:.4f}]\")\n",
    "        else:\n",
    "            print(\"ΔC-index 95% CI: NA\")\n",
    "\n",
    "# =========================\n",
    "rows = []\n",
    "for j, m in enumerate(model_names):\n",
    "    # OR (Test, per 10% ↑)\n",
    "    s_pred_full = pd.Series(S_test[:, j], index=common_test_idx)\n",
    "    y_full      = pd.Series(y_test_all, index=common_test_idx, name=\"label\")\n",
    "\n",
    "    pred10 = (s_pred_full.to_numpy(dtype=float) * 10.0)\n",
    "    OR_a = ORa_low = ORa_hi = ORa_p = np.nan\n",
    "    try:\n",
    "        mask_logit = (\n",
    "            test_cov_mask.to_numpy()[common_test_idx] &\n",
    "            np.isfinite(pred10) & np.isfinite(y_full.to_numpy(dtype=float))\n",
    "        )\n",
    "        if mask_logit.any():\n",
    "            Xlog = X_test_base.iloc[common_test_idx[mask_logit]].copy()\n",
    "            Xlog = sm.add_constant(pd.concat([pd.Series(pred10[mask_logit], name=\"pred10\", index=Xlog.index), Xlog], axis=1))\n",
    "            ylog = pd.Series(y_full.to_numpy(dtype=float)[mask_logit], index=Xlog.index, name=\"label_det\")\n",
    "            lg = sm.Logit(ylog, Xlog).fit(disp=False)\n",
    "            OR_a = float(np.exp(lg.params[\"pred10\"]))\n",
    "            ci = lg.conf_int().loc[\"pred10\"]\n",
    "            ORa_low, ORa_hi = float(np.exp(ci[0])), float(np.exp(ci[1]))\n",
    "            ORa_p = fmt_p(lg.pvalues[\"pred10\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # HR (Future, per 10% ↑)\n",
    "    HR_a = HRa_low = HRa_hi = HRa_p = np.nan\n",
    "    n_fut_used = 0\n",
    "    if have_future and m in fut_series:\n",
    "        r_pred_full = pd.Series(R_fut[:, j], index=common_fut_idx)\n",
    "        pred10_f = (r_pred_full.to_numpy(dtype=float) * 10.0)\n",
    "        try:\n",
    "            mask_cox = (\n",
    "                fut_cov_mask.to_numpy()[common_fut_idx] &\n",
    "                np.isfinite(pred10_f) &\n",
    "                np.isfinite(t_fut_all) &\n",
    "                np.isfinite(e_fut_all)\n",
    "            )\n",
    "            n_fut_used = int(mask_cox.sum())\n",
    "            if mask_cox.any():\n",
    "                Xcox = X_fut_base.iloc[common_fut_idx[mask_cox]].copy()\n",
    "                df_cox = pd.concat(\n",
    "                    [\n",
    "                        pd.Series(t_fut_all[mask_cox], name=\"obs_time\", index=Xcox.index),\n",
    "                        pd.Series(e_fut_all[mask_cox], name=\"event\", index=Xcox.index),\n",
    "                        pd.Series(pred10_f[mask_cox],  name=\"pred10\", index=Xcox.index),\n",
    "                        Xcox\n",
    "                    ],\n",
    "                    axis=1\n",
    "                )\n",
    "                cph = CoxPHFitter()\n",
    "                cph.fit(df_cox, duration_col=\"obs_time\", event_col=\"event\", show_progress=False)\n",
    "                HR_a = float(np.exp(cph.params_[\"pred10\"]))\n",
    "                ci = cph.confidence_intervals_.loc[\"pred10\"]\n",
    "                HRa_low, HRa_hi = float(np.exp(ci[0])), float(np.exp(ci[1]))\n",
    "                HRa_p = fmt_p(cph.summary.loc[\"pred10\",\"p\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    rows.append(dict(\n",
    "        model_desc = m,\n",
    "        Test_AUC_MODEL = None if pd.isna(auc_models[j]) else float(f\"{auc_models[j]:.3f}\"),\n",
    "        Test_AUC_CAIDE = None if pd.isna(auc_caide) else float(f\"{auc_caide:.3f}\"),\n",
    "        OR_adj = OR_a, OR_adj_low = ORa_low, OR_adj_hi = ORa_hi, OR_adj_p = ORa_p,\n",
    "        Future_cindex_MODEL = None if (not have_future or pd.isna(cidx_models[j])) else float(f\"{cidx_models[j]:.3f}\"),\n",
    "        Future_cindex_CAIDE = None if (not have_future or pd.isna(cidx_caide)) else float(f\"{cidx_caide:.3f}\"),\n",
    "        HR_adj = HR_a, HR_adj_low = HRa_low, HR_adj_hi = HRa_hi, HRa_p = HRa_p,\n",
    "        n_test_used = int(len(common_test_idx)),\n",
    "        n_fut_used  = int(n_fut_used if have_future else 0),\n",
    "    ))\n",
    "\n",
    "summary = pd.DataFrame(rows).sort_values(\"model_desc\").reset_index(drop=True)\n",
    "for col in [\"OR_adj\",\"OR_adj_low\",\"OR_adj_hi\",\"HR_adj\",\"HR_adj_low\",\"HR_adj_hi\"]:\n",
    "    if col in summary.columns:\n",
    "        summary[col] = summary[col].apply(lambda v: \"\" if pd.isna(v) else f\"{float(v):.3f}\")\n",
    "\n",
    "summary.to_csv(OUT_SUMMARY, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n[Saved] {OUT_SUMMARY}\\n\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e800218-7fe6-46de-b378-9d231a3e5074",
   "metadata": {},
   "source": [
    "# detailed performance metrics bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4a1ec-642b-4553-a3f1-2d974577c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Test-set metrics (incl. AUROC) at validation Youden-J thresholds with single-cycle bootstrap for all models.\n",
    "\n",
    "- Thresholds: from youden_thresholds.csv (split='valid')\n",
    "- Models: defined by ARCHES × FTS, pick one row per (arch, ft) (ties -> highest AUC in csv)\n",
    "- Test predictions: /home/hch/dementia/infer_out/{MODEL_DESC}/test_preds.csv (expects: idx, label, pred)\n",
    "- Evaluation:\n",
    "  * Use intersection of idx across all selected models\n",
    "  * Compute Accuracy, Sensitivity, Specificity, PPV, NPV, F1, AUROC\n",
    "  * One bootstrap cycle for all models together (N_BOOT=2000), same resample indices\n",
    "- Output: single table with point estimates and 95% CIs (rounded to 3 decimals)\n",
    "\"\"\"\n",
    "\n",
    "import os, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ---------------------------\n",
    "THRESH_CSV = Path(\"./youden_thresholds.csv\")\n",
    "INFER_ROOT = Path(\"/home/hch/dementia/infer_out\")\n",
    "N_BOOT = 2000\n",
    "RNG_SEED = 42\n",
    "OUT_CSV = Path(\"./test_metrics_bootstrap.csv\")\n",
    "\n",
    "# 모델 스펙(arch, ft) 선택\n",
    "ARCHES = ['retfound', 'mae', 'openclip', 'dinov2', 'dinov3', 'retfound_dinov2']\n",
    "FTS    = ['linear', 'partial', 'lora']\n",
    "\n",
    "# ---------------------------\n",
    "def ft_blks_for(ft: str):\n",
    "    if ft == 'partial': return 4\n",
    "    if ft == 'lora':    return 'full'\n",
    "    return None\n",
    "\n",
    "def model_desc_from_csv_row(row: pd.Series) -> str:\n",
    "    arch = str(row['arch']); ft = str(row['ft'])\n",
    "    desc = f\"{arch}_{ft}\"\n",
    "    if ft == 'partial':\n",
    "        desc += f\"_ft_{row['ft_blks']}\"\n",
    "    elif ft == 'lora':\n",
    "        lrk = str(row.get('lora_rank', ''))\n",
    "        desc += f\"_rank_{lrk}_ft_{row['ft_blks']}\"\n",
    "    return desc\n",
    "\n",
    "def pick_threshold_row(thr_df: pd.DataFrame, arch: str, ft: str) -> pd.Series | None:\n",
    "    df = thr_df.copy()\n",
    "    df = df.query(\"arch == @arch and ft == @ft\")\n",
    "    if ft == 'partial':\n",
    "        df = df.query(\"ft_blks == '4'\")\n",
    "    elif ft == 'lora':\n",
    "        df = df.query(\"ft_blks == 'full'\")\n",
    "    # linear은 ft_blks 조건 없음\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    if 'auc' in df.columns:\n",
    "        df = df.sort_values('auc', ascending=False)\n",
    "    return df.iloc[0]\n",
    "\n",
    "def safe_div(num, den):\n",
    "    num = float(num); den = float(den)\n",
    "    if not np.isfinite(den) or den == 0: return np.nan\n",
    "    return num / den\n",
    "\n",
    "def counts_to_metrics(tp, fp, tn, fn):\n",
    "    acc  = safe_div(tp + tn, tp + fp + tn + fn)\n",
    "    sens = safe_div(tp, tp + fn)          # TPR\n",
    "    spec = safe_div(tn, tn + fp)          # TNR\n",
    "    ppv  = safe_div(tp, tp + fp)          # Precision\n",
    "    npv  = safe_div(tn, tn + fn)\n",
    "    f1   = safe_div(2*tp, 2*tp + fp + fn)\n",
    "    return acc, sens, spec, ppv, npv, f1\n",
    "\n",
    "def safe_roc_auc(y_true: np.ndarray, y_prob: np.ndarray):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    if (np.unique(y_true).size < 2):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(roc_auc_score(y_true, y_prob))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def format3(x):\n",
    "    if x is None or (isinstance(x, float) and (np.isnan(x) or not np.isfinite(x))):\n",
    "        return \"\"\n",
    "    return f\"{x:.3f}\"\n",
    "\n",
    "def ci_str(low, high):\n",
    "    if (low is None) or (high is None) or any(\n",
    "        (v is None) or (isinstance(v,float) and (not np.isfinite(v))) for v in [low, high]\n",
    "    ):\n",
    "        return \"\"\n",
    "    return f\"[{low:.3f}, {high:.3f}]\"\n",
    "\n",
    "# ---------------------------\n",
    "assert THRESH_CSV.exists(), f\"youden_thresholds.csv not found at: {THRESH_CSV}\"\n",
    "thr_df = pd.read_csv(THRESH_CSV)\n",
    "for col in [\"arch\",\"ft\",\"ft_blks\",\"split\"]:\n",
    "    if col in thr_df.columns:\n",
    "        thr_df[col] = thr_df[col].astype(str)\n",
    "thr_df = thr_df.query(\"split == 'valid'\").copy()\n",
    "\n",
    "# ---------------------------\n",
    "selected = []\n",
    "for arch in ARCHES:\n",
    "    for ft in FTS:\n",
    "        row = pick_threshold_row(thr_df, arch, ft)\n",
    "        if row is None:\n",
    "            continue\n",
    "        if ft == 'partial' and str(row['ft_blks']) != '4':\n",
    "            continue\n",
    "        if ft == 'lora' and str(row['ft_blks']) != 'full':\n",
    "            continue\n",
    "        desc = model_desc_from_csv_row(row)\n",
    "        thr  = float(row['youden_thr'])\n",
    "        selected.append({\n",
    "            \"arch\": arch,\n",
    "            \"ft\": ft,\n",
    "            \"model_desc\": desc,\n",
    "            \"threshold\": thr\n",
    "        })\n",
    "\n",
    "tmp_df = pd.DataFrame(selected).drop_duplicates(subset=[\"model_desc\"]).reset_index(drop=True)\n",
    "selected = tmp_df.to_dict(orient=\"records\")\n",
    "if len(selected) == 0:\n",
    "    raise RuntimeError(\"no models selected. check youden_thresholds.csv and ARCHES/FTS.\")\n",
    "\n",
    "print(f\"number of selected models: {len(selected)}\")\n",
    "for s in selected:\n",
    "    print(f\" - {s['model_desc']} (thr={s['threshold']:.6f})\")\n",
    "\n",
    "# ---------------------------\n",
    "preds_by_model = {}\n",
    "idx_sets = []\n",
    "\n",
    "for s in selected:\n",
    "    desc = s[\"model_desc\"]\n",
    "    test_csv = INFER_ROOT / desc / \"test_preds.csv\"\n",
    "    if not test_csv.exists():\n",
    "        print(f\"[SKIP] missing: {test_csv}\")\n",
    "        continue\n",
    "    df = pd.read_csv(test_csv)\n",
    "    for col in [\"idx\", \"label\", \"pred\"]:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"{test_csv}, {col}\")\n",
    "    df = df[[\"idx\",\"label\",\"pred\"]].copy()\n",
    "    df[\"idx\"] = df[\"idx\"].astype(int)\n",
    "    df = df.dropna(subset=[\"label\",\"pred\"]).reset_index(drop=True)\n",
    "    preds_by_model[desc] = df\n",
    "    idx_sets.append(set(df[\"idx\"].tolist()))\n",
    "\n",
    "if len(preds_by_model) == 0:\n",
    "    raise RuntimeError(\"no models with test_preds.csv\")\n",
    "\n",
    "common_idx = set.intersection(*idx_sets) if len(idx_sets) > 1 else idx_sets[0]\n",
    "common_idx = sorted(list(common_idx))\n",
    "if len(common_idx) == 0:\n",
    "    raise RuntimeError(\"error\")\n",
    "print(f\"samples: {len(common_idx)}\")\n",
    "\n",
    "data_by_model = {}\n",
    "for s in selected:\n",
    "    desc = s[\"model_desc\"]; thr = s[\"threshold\"]\n",
    "    if desc not in preds_by_model:\n",
    "        continue\n",
    "    df = preds_by_model[desc]\n",
    "    sub = df[df[\"idx\"].isin(common_idx)].copy()\n",
    "    sub = sub.set_index(\"idx\").loc[common_idx].reset_index()\n",
    "    y_true = sub[\"label\"].astype(int).to_numpy()\n",
    "    y_prob = sub[\"pred\"].astype(float).to_numpy()\n",
    "    data_by_model[desc] = {\n",
    "        \"threshold\": thr,\n",
    "        \"y_true\": y_true,\n",
    "        \"y_prob\": y_prob\n",
    "    }\n",
    "\n",
    "if len(data_by_model) == 0:\n",
    "    raise RuntimeError(\"error\")\n",
    "\n",
    "# ---------------------------\n",
    "def metrics_on_threshold(y_true, y_prob, thr):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    tp = int(((y_true == 1) & (y_pred == 1)).sum())\n",
    "    fp = int(((y_true == 0) & (y_pred == 1)).sum())\n",
    "    tn = int(((y_true == 0) & (y_pred == 0)).sum())\n",
    "    fn = int(((y_true == 1) & (y_pred == 0)).sum())\n",
    "    acc, sens, spec, ppv, npv, f1 = counts_to_metrics(tp, fp, tn, fn)\n",
    "    return {\n",
    "        \"TP\": tp, \"FP\": fp, \"TN\": tn, \"FN\": fn,\n",
    "        \"Accuracy\": acc, \"Sensitivity\": sens, \"Specificity\": spec,\n",
    "        \"PPV\": ppv, \"NPV\": npv, \"F1\": f1\n",
    "    }\n",
    "\n",
    "point_estimates = {}\n",
    "for desc, pack in data_by_model.items():\n",
    "    pe = metrics_on_threshold(pack[\"y_true\"], pack[\"y_prob\"], pack[\"threshold\"])\n",
    "    pe[\"AUROC\"] = safe_roc_auc(pack[\"y_true\"], pack[\"y_prob\"])\n",
    "    point_estimates[desc] = pe\n",
    "\n",
    "# ---------------------------\n",
    "rng = np.random.default_rng(RNG_SEED)\n",
    "n = len(common_idx)\n",
    "\n",
    "metrics_list = [\"AUROC\",\"Accuracy\",\"Sensitivity\",\"Specificity\",\"PPV\",\"NPV\",\"F1\"]\n",
    "boot_store = {m: {desc: np.full(N_BOOT, np.nan, dtype=float) for desc in data_by_model.keys()} \n",
    "              for m in metrics_list}\n",
    "\n",
    "for b in trange(N_BOOT, desc=\"Bootstrapping (single-cycle for all models)\"):\n",
    "    sample_idx = rng.integers(low=0, high=n, size=n, endpoint=False)\n",
    "    for desc, pack in data_by_model.items():\n",
    "        y_t = pack[\"y_true\"][sample_idx]\n",
    "        y_p = pack[\"y_prob\"][sample_idx]\n",
    "        thr = pack[\"threshold\"]\n",
    "        # AUROC\n",
    "        boot_store[\"AUROC\"][desc][b] = safe_roc_auc(y_t, y_p)\n",
    "        # Threshold-based metrics\n",
    "        m = metrics_on_threshold(y_t, y_p, thr)\n",
    "        for k in [\"Accuracy\",\"Sensitivity\",\"Specificity\",\"PPV\",\"NPV\",\"F1\"]:\n",
    "            boot_store[k][desc][b] = m[k]\n",
    "\n",
    "def ci95(arr):\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    arr = arr[np.isfinite(arr)]\n",
    "    if arr.size == 0:\n",
    "        return (np.nan, np.nan)\n",
    "    return (np.percentile(arr, 2.5), np.percentile(arr, 97.5))\n",
    "\n",
    "# ---------------------------\n",
    "rows = []\n",
    "for s in selected:\n",
    "    desc = s[\"model_desc\"]\n",
    "    if desc not in data_by_model:\n",
    "        continue\n",
    "    pe = point_estimates[desc]\n",
    "    row = {\n",
    "        \"model_desc\": desc,\n",
    "        \"threshold\": round(s[\"threshold\"], 6),\n",
    "    }\n",
    "    au_point = pe.get(\"AUROC\", np.nan)\n",
    "    au_low, au_high = ci95(boot_store[\"AUROC\"][desc])\n",
    "    row[\"AUROC\"] = format3(au_point)\n",
    "    row[\"AUROC 95% CI\"] = ci_str(au_low, au_high)\n",
    "    for metric in [\"Accuracy\",\"Sensitivity\",\"Specificity\",\"PPV\",\"NPV\",\"F1\"]:\n",
    "        point = pe[metric]\n",
    "        low, high = ci95(boot_store[metric][desc])\n",
    "        row[metric] = format3(point)\n",
    "        row[f\"{metric} 95% CI\"] = ci_str(low, high)\n",
    "    rows.append(row)\n",
    "\n",
    "res_df = pd.DataFrame(rows)\n",
    "cols_order = [\"model_desc\",\"threshold\",\n",
    "              \"AUROC\",\"AUROC 95% CI\",\n",
    "              \"Accuracy\",\"Accuracy 95% CI\",\n",
    "              \"Sensitivity\",\"Sensitivity 95% CI\",\n",
    "              \"Specificity\",\"Specificity 95% CI\",\n",
    "              \"PPV\",\"PPV 95% CI\",\n",
    "              \"NPV\",\"NPV 95% CI\",\n",
    "              \"F1\",\"F1 95% CI\"]\n",
    "res_df = res_df.reindex(columns=cols_order)\n",
    "\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "res_df.to_csv(OUT_CSV, index=False)\n",
    "print(\"\\n=== Test metrics incl. AUROC @ validation Youden-J thresholds (single-cycle bootstrap) ===\")\n",
    "print(res_df.to_string(index=False))\n",
    "print(f\"\\n[Saved] {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9770ab-e110-4f51-91bf-e4cb4d5863f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Format 'test_metrics_bootstrap.csv' + 'caide_test_metrics_threshold5.csv' to match the layout of Supplementary Table S2.\n",
    "\n",
    "Output columns:\n",
    "  Model | Fine-tuning method | Accuracy (95% CI) | Sensitivity (95% CI) | Specificity (95% CI)\n",
    "        | PPV (95% CI) | NPV (95% CI) | F1-score (95% CI)\n",
    "\n",
    "- Model order: OpenCLIP, MAE, DINOv3, RETFound-MAE, RETFound-DINOv2\n",
    "- Fine-tuning rows per Model: Classifier only (linear), Partial finetuning (partial), LoRA tuning (lora)\n",
    "- Cells show \"point\" in first line and \"(low - high)\" in second line. Missing combos remain blank.\n",
    "\n",
    "Reads:\n",
    "  ./test_metrics_bootstrap.csv\n",
    "  ./caide_test_metrics_threshold5.csv\n",
    "\n",
    "Saves:\n",
    "  ./supp_table_S2_formatted.csv\n",
    "\"\"\"\n",
    "\n",
    "import os, warnings, re\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------\n",
    "# Paths\n",
    "# -----------------------\n",
    "TEST_METRICS_CSV  = Path(\"./test_metrics_bootstrap.csv\")\n",
    "CAIDE_METRICS_CSV = Path(\"./caide_test_metrics_threshold5.csv\")\n",
    "OUT_CSV           = Path(\"./supp_table_S2_formatted.csv\")\n",
    "\n",
    "assert TEST_METRICS_CSV.exists(), f\"Not found: {TEST_METRICS_CSV}\"\n",
    "assert CAIDE_METRICS_CSV.exists(), f\"Not found: {CAIDE_METRICS_CSV}\"\n",
    "\n",
    "df = pd.read_csv(TEST_METRICS_CSV)\n",
    "caide = pd.read_csv(CAIDE_METRICS_CSV)\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def parse_model_desc(desc: str):\n",
    "    \"\"\"\n",
    "    Parse model_desc like:\n",
    "      openclip_linear\n",
    "      mae_partial_ft_4\n",
    "      dinov3_lora_rank_4_ft_full\n",
    "      retfound_dinov2_partial_ft_4\n",
    "      retfound_mae_linear\n",
    "    Return (arch_key, ft_key)\n",
    "    \"\"\"\n",
    "    parts = desc.split(\"_\")\n",
    "    if parts[0] == \"retfound\" and len(parts) >= 2 and parts[1] in (\"dinov2\", \"mae\"):\n",
    "        arch_key = f\"{parts[0]}_{parts[1]}\"  # retfound_dinov2, retfound_mae\n",
    "        # ft is next token\n",
    "        ft_key = parts[2] if len(parts) >= 3 else \"\"\n",
    "    else:\n",
    "        arch_key = parts[0] if len(parts) >= 1 else \"\"\n",
    "        ft_key = parts[1] if len(parts) >= 2 else \"\"\n",
    "    return arch_key, ft_key\n",
    "\n",
    "ARCH_DISPLAY = {\n",
    "    \"openclip\": \"OpenCLIP\",\n",
    "    \"mae\": \"MAE\",\n",
    "    \"dinov3\": \"DINOv3\",\n",
    "    \"dinov2\": \"DINOv2\",            # in case\n",
    "    \"retfound\": \"RETFound-MAE\",\n",
    "    \"retfound_dinov2\": \"RETFound-DINOv2\",\n",
    "    \"retfound\": \"RETFound\",        # fallback\n",
    "}\n",
    "\n",
    "FT_DISPLAY = {\n",
    "    \"linear\": \"Classifier only\",\n",
    "    \"partial\": \"Partial finetuning\",\n",
    "    \"lora\": \"LoRA tuning\",\n",
    "}\n",
    "\n",
    "MODEL_ORDER = [\"openclip\", \"mae\", \"dinov3\", \"retfound\", \"retfound_dinov2\"]\n",
    "FT_ORDER    = [\"linear\", \"partial\", \"lora\"]\n",
    "\n",
    "METRICS = [\"Accuracy\", \"Sensitivity\", \"Specificity\", \"PPV\", \"NPV\", \"F1\"]\n",
    "\n",
    "def normalize_ci_text(ci_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert '[0.680, 0.730]' -> '0.680 - 0.730'\n",
    "    \"\"\"\n",
    "    if not isinstance(ci_str, str) or ci_str.strip() == \"\":\n",
    "        return \"\"\n",
    "    s = ci_str.strip()\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        s = s[1:-1]\n",
    "    s = re.sub(r\"\\s*,\\s*\", \" - \", s)\n",
    "    return s\n",
    "\n",
    "def cell(point, ci):\n",
    "    \"\"\"\n",
    "    Format a cell with point on first line and (low - high) on next line.\n",
    "    If both missing -> ''.\n",
    "    \"\"\"\n",
    "    p = \"\" if (point is None or (isinstance(point, float) and not np.isfinite(point)) or str(point).strip()==\"\") else str(point)\n",
    "    c = normalize_ci_text(ci)\n",
    "    if p == \"\" and c == \"\": \n",
    "        return \"\"\n",
    "    return f\"{p}\\n({c})\" if c != \"\" else p\n",
    "\n",
    "# -----------------------\n",
    "# Preprocess: attach parsed keys\n",
    "# -----------------------\n",
    "df = df.copy()\n",
    "df[\"arch_key\"] = \"\"\n",
    "df[\"ft_key\"] = \"\"\n",
    "for i, r in df.iterrows():\n",
    "    a, f = parse_model_desc(str(r[\"model_desc\"]))\n",
    "    df.at[i, \"arch_key\"] = a\n",
    "    df.at[i, \"ft_key\"] = f\n",
    "\n",
    "# -----------------------\n",
    "# Build formatted table rows\n",
    "# -----------------------\n",
    "rows = []\n",
    "for arch_key in MODEL_ORDER:\n",
    "    for k, ft in enumerate(FT_ORDER):\n",
    "        sub = df[(df[\"arch_key\"] == arch_key) & (df[\"ft_key\"] == ft)]\n",
    "        model_cell = ARCH_DISPLAY.get(arch_key, arch_key) if k == 0 else \"\"\n",
    "        ft_cell = FT_DISPLAY.get(ft, ft)\n",
    "\n",
    "        row = {\n",
    "            \"Model\": model_cell,\n",
    "            \"Fine-tuning method\": ft_cell,\n",
    "        }\n",
    "\n",
    "        if len(sub) == 1:\n",
    "            s = sub.iloc[0]\n",
    "            for m in METRICS:\n",
    "                row[f\"{m} (95% CI)\"] = cell(s.get(m, \"\"), s.get(f\"{m} 95% CI\", \"\"))\n",
    "        else:\n",
    "            for m in METRICS:\n",
    "                row[f\"{m} (95% CI)\"] = \"\"\n",
    "        rows.append(row)\n",
    "\n",
    "# -----------------------\n",
    "# Append CAIDE row at bottom\n",
    "# -----------------------\n",
    "if len(caide) >= 1:\n",
    "    c = caide.iloc[0]\n",
    "    caide_row = {\"Model\": \"CAIDE score\", \"Fine-tuning method\": \"\"}\n",
    "    for m in METRICS:\n",
    "        caide_row[f\"{m} (95% CI)\"] = cell(c.get(m, \"\"), c.get(f\"{m} 95% CI\", \"\"))\n",
    "    rows.append(caide_row)\n",
    "\n",
    "# -----------------------\n",
    "# Create DataFrame & save\n",
    "# -----------------------\n",
    "out_cols = [\"Model\", \"Fine-tuning method\"] + [f\"{m} (95% CI)\" for m in METRICS]\n",
    "out_df = pd.DataFrame(rows, columns=out_cols)\n",
    "\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "out_df.to_csv(OUT_CSV, index=False)\n",
    "print(\"\\n=== Supplementary Table S2 (formatted) ===\")\n",
    "print(out_df.to_string(index=False))\n",
    "print(f\"\\n[Saved] {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dfd42c-775d-4e65-be11-1e5775fc639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "CAIDE-only detailed performance on TEST set (threshold = 5 points)\n",
    "- Metrics: AUROC + (Accuracy, Sensitivity, Specificity, PPV, NPV, F1)\n",
    "- 2000× bootstrap for 95% CI (single cycle, CAIDE only)\n",
    "- Output: ./caide_test_metrics_threshold5.csv\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# =========================\n",
    "WORK_DIR = \"/home/hch/dementia\"\n",
    "os.chdir(WORK_DIR)\n",
    "\n",
    "IN_CSV  = Path(\"dementia_detection.csv\")  \n",
    "OUT_CSV = Path(\"./caide_test_metrics_threshold5.csv\")\n",
    "\n",
    "N_BOOT   = 2000\n",
    "RNG_SEED = 2025\n",
    "CAIDE_THRESHOLD = 6  # points\n",
    "\n",
    "# =========================\n",
    "def add_common_covs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    if \"SEXINT\" not in out.columns:\n",
    "        if \"SEX\" in out.columns:\n",
    "            out[\"SEXINT\"] = (out[\"SEX\"] == \"M\").astype(int)\n",
    "        else:\n",
    "            out[\"SEXINT\"] = np.nan\n",
    "\n",
    "    if \"EXERCISE_STATUS\" in out.columns:\n",
    "        out[\"EXERCISE_STATUS\"] = pd.to_numeric(out[\"EXERCISE_STATUS\"], errors=\"coerce\")\n",
    "    else:\n",
    "        out[\"EXERCISE_STATUS\"] = np.nan\n",
    "\n",
    "    for c in [\"STDY_AGE\", \"cholesterol_updated\", \"sbp\", \"bmi\"]:\n",
    "        if c in out.columns:\n",
    "            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "        else:\n",
    "            out[c] = np.nan\n",
    "    return out\n",
    "\n",
    "def calc_caide_napoe(frame: pd.DataFrame) -> pd.Series:\n",
    "    x = frame.copy()\n",
    "    for col in [\"STDY_AGE\",\"SEXINT\",\"sbp\",\"bmi\",\"cholesterol_updated\",\"EXERCISE_STATUS\"]:\n",
    "        if col in x.columns:\n",
    "            x[col] = pd.to_numeric(x[col], errors=\"coerce\")\n",
    "        else:\n",
    "            x[col] = np.nan\n",
    "\n",
    "    age = x[\"STDY_AGE\"]\n",
    "    age_pts = np.select([age < 47, (47 <= age) & (age <= 53), age > 53], [0, 3, 4], default=np.nan)\n",
    "    sex_pts = np.where(x[\"SEXINT\"] == 1, 1, 0)\n",
    "    edu_pts = np.zeros(len(x), dtype=float)  \n",
    "    sbp_pts = np.where(x[\"sbp\"] >= 140, 2, 0)\n",
    "    bmi_pts = np.where(x[\"bmi\"] >= 30, 2, 0)\n",
    "    chol_mmol = x[\"cholesterol_updated\"] * 0.02586\n",
    "    chol_pts  = np.where(chol_mmol >= 6.5, 2, 0)\n",
    "    ex = x[\"EXERCISE_STATUS\"]\n",
    "    pa_pts = np.where(ex >= 2, 0, 1)  \n",
    "\n",
    "    score = age_pts + sex_pts + edu_pts + sbp_pts + bmi_pts + chol_pts + pa_pts\n",
    "    return pd.Series(score, index=frame.index, name=\"CAIDE_noAPOE\")\n",
    "\n",
    "def caide_valid_mask(frame: pd.DataFrame) -> pd.Series:\n",
    "    req = [\"STDY_AGE\",\"SEXINT\",\"sbp\",\"bmi\",\"cholesterol_updated\",\"EXERCISE_STATUS\"]\n",
    "    return frame[req].notna().all(axis=1)\n",
    "\n",
    "def safe_div(num, den):\n",
    "    num = float(num); den = float(den)\n",
    "    if not np.isfinite(den) or den == 0: return np.nan\n",
    "    return num / den\n",
    "\n",
    "def counts_to_metrics(tp, fp, tn, fn):\n",
    "    acc  = safe_div(tp + tn, tp + fp + tn + fn)\n",
    "    sens = safe_div(tp, tp + fn)          # TPR\n",
    "    spec = safe_div(tn, tn + fp)          # TNR\n",
    "    ppv  = safe_div(tp, tp + fp)          # Precision\n",
    "    npv  = safe_div(tn, tn + fn)\n",
    "    f1   = safe_div(2*tp, 2*tp + fp + fn)\n",
    "    return acc, sens, spec, ppv, npv, f1\n",
    "\n",
    "def safe_auc(y_true: np.ndarray, y_prob: np.ndarray):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    if np.unique(y_true).size < 2:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(roc_auc_score(y_true, y_prob))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def format3(x):\n",
    "    if x is None or (isinstance(x, float) and (np.isnan(x) or not np.isfinite(x))):\n",
    "        return \"\"\n",
    "    return f\"{x:.3f}\"\n",
    "\n",
    "def ci_str(lo, hi):\n",
    "    if any((v is None) or (isinstance(v, float) and (not np.isfinite(v))) for v in [lo, hi]):\n",
    "        return \"\"\n",
    "    return f\"[{lo:.3f}, {hi:.3f}]\"\n",
    "\n",
    "def metrics_from_arrays(y_true: np.ndarray, caide_score: np.ndarray, thr: float):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = (caide_score >= thr).astype(int)\n",
    "    tp = int(((y_true == 1) & (y_pred == 1)).sum())\n",
    "    fp = int(((y_true == 0) & (y_pred == 1)).sum())\n",
    "    tn = int(((y_true == 0) & (y_pred == 0)).sum())\n",
    "    fn = int(((y_true == 1) & (y_pred == 0)).sum())\n",
    "    acc, sens, spec, ppv, npv, f1 = counts_to_metrics(tp, fp, tn, fn)\n",
    "    auc = safe_auc(y_true, caide_score)  \n",
    "    return {\n",
    "        \"TP\": tp, \"FP\": fp, \"TN\": tn, \"FN\": fn,\n",
    "        \"AUROC\": auc,\n",
    "        \"Accuracy\": acc, \"Sensitivity\": sens, \"Specificity\": spec,\n",
    "        \"PPV\": ppv, \"NPV\": npv, \"F1\": f1\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "assert IN_CSV.exists(), f\"Input not found: {IN_CSV}\"\n",
    "det_all = pd.read_csv(IN_CSV, low_memory=False)\n",
    "\n",
    "if \"test\" not in det_all.columns:\n",
    "    raise ValueError(\"error\")\n",
    "det_test = det_all[det_all[\"test\"] == True].reset_index(drop=True)\n",
    "\n",
    "det_test = add_common_covs(det_test)\n",
    "caide_score = calc_caide_napoe(det_test)               \n",
    "valid_mask  = caide_valid_mask(det_test)               \n",
    "if \"label\" not in det_test.columns:\n",
    "    raise ValueError(\"error\")\n",
    "label_valid = det_test[\"label\"].notna()\n",
    "\n",
    "mask = valid_mask & label_valid\n",
    "det_used = det_test.loc[mask].copy()\n",
    "\n",
    "y_true = det_used[\"label\"].astype(int).to_numpy()\n",
    "s_caide = caide_score.loc[mask].astype(float).to_numpy()\n",
    "n = len(det_used)\n",
    "if n == 0:\n",
    "    raise RuntimeError(\"error\")\n",
    "\n",
    "print(f\"CAIDE test-set evaluation (threshold = {CAIDE_THRESHOLD})\")\n",
    "print(f\"- usable samples: n = {n}\")\n",
    "\n",
    "# =========================\n",
    "point = metrics_from_arrays(y_true, s_caide, CAIDE_THRESHOLD)\n",
    "\n",
    "# =========================\n",
    "rng = np.random.default_rng(RNG_SEED)\n",
    "\n",
    "boot = {\n",
    "    \"AUROC\": np.full(N_BOOT, np.nan, dtype=float),\n",
    "    \"Accuracy\": np.full(N_BOOT, np.nan, dtype=float),\n",
    "    \"Sensitivity\": np.full(N_BOOT, np.nan, dtype=float),\n",
    "    \"Specificity\": np.full(N_BOOT, np.nan, dtype=float),\n",
    "    \"PPV\": np.full(N_BOOT, np.nan, dtype=float),\n",
    "    \"NPV\": np.full(N_BOOT, np.nan, dtype=float),\n",
    "    \"F1\": np.full(N_BOOT, np.nan, dtype=float),\n",
    "}\n",
    "\n",
    "for b in trange(N_BOOT, desc=\"Bootstrapping (CAIDE only)\"):\n",
    "    idx = rng.integers(0, n, size=n)\n",
    "    yb = y_true[idx]\n",
    "    sb = s_caide[idx]\n",
    "    m = metrics_from_arrays(yb, sb, CAIDE_THRESHOLD)\n",
    "    for k in boot.keys():\n",
    "        boot[k][b] = m[k]\n",
    "\n",
    "def ci95(arr):\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    arr = arr[np.isfinite(arr)]\n",
    "    if arr.size == 0: return (np.nan, np.nan)\n",
    "    return (np.percentile(arr, 2.5), np.percentile(arr, 97.5))\n",
    "\n",
    "# =========================\n",
    "rows = []\n",
    "row = {\n",
    "    \"Metric\": \"CAIDE (threshold=5) - TEST\",\n",
    "    \"n\": int(n),\n",
    "    \"TP\": int(point[\"TP\"]),\n",
    "    \"FP\": int(point[\"FP\"]),\n",
    "    \"TN\": int(point[\"TN\"]),\n",
    "    \"FN\": int(point[\"FN\"]),\n",
    "}\n",
    "for metric in [\"AUROC\",\"Accuracy\",\"Sensitivity\",\"Specificity\",\"PPV\",\"NPV\",\"F1\"]:\n",
    "    lo, hi = ci95(boot[metric])\n",
    "    row[metric] = format3(point[metric])\n",
    "    row[f\"{metric} 95% CI\"] = ci_str(lo, hi)\n",
    "rows.append(row)\n",
    "\n",
    "res = pd.DataFrame(rows, columns=[\n",
    "    \"Metric\",\"n\",\"TP\",\"FP\",\"TN\",\"FN\",\n",
    "    \"AUROC\",\"AUROC 95% CI\",\n",
    "    \"Accuracy\",\"Accuracy 95% CI\",\n",
    "    \"Sensitivity\",\"Sensitivity 95% CI\",\n",
    "    \"Specificity\",\"Specificity 95% CI\",\n",
    "    \"PPV\",\"PPV 95% CI\",\n",
    "    \"NPV\",\"NPV 95% CI\",\n",
    "    \"F1\",\"F1 95% CI\"\n",
    "])\n",
    "\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "res.to_csv(OUT_CSV, index=False)\n",
    "print(\"\\n=== CAIDE detailed performance (TEST, thr=5) ===\")\n",
    "print(res.to_string(index=False))\n",
    "print(f\"\\n[Saved] {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5774c-d2e6-4b28-8c3d-5d6dbb92396e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
