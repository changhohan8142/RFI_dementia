{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfdf69a-ceee-4942-92b2-106d5bc591eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Grad-CAM export — ALL ARCH × FT combos (use thresholds from youden_thresholds.csv)\n",
    "# - Replicates the exact pipeline you ran for \"retfound_partial_ft_4\"\n",
    "# - For each (arch, ft) combo:\n",
    "#     * Read BEST_THRESH from youden_thresholds.csv (split='valid', ft_blks mapping)\n",
    "#     * Load model checkpoint from /home/kjw/Projects/dementia/ckpts/{MODEL_DESC}/ckpt.pth.tar\n",
    "#     * Read INFER CSVs from /home/hch/dementia/infer_out/{MODEL_DESC}\n",
    "#     * Filter TPs by BEST_THRESH (TEST, FUTURE)\n",
    "#     * Save origin_images.pth & saliency_map.pth under ./tensors/{MODEL_DESC}_test|_future\n",
    "#     * Save representative Grad-CAM (L/R heatmap & overlay) under ./rep_gradcam_lr/{MODEL_DESC}\n",
    "#     * Compute Mask metrics & save RESULTS_*.csv\n",
    "#     * Compute ATTN_summary_TEST/FUTURE.csv\n",
    "# - Note: if multiple lora_rank exist for a (arch,lora,ft_blks=\"full\"), pick the one with highest AUC.\n",
    "\n",
    "# %%\n",
    "import os, sys, math, json, random, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# ----- project-local imports (same as trainer.py / gradcam_dementia.py)\n",
    "WORK_DIR   = \"/home/hch/dementia\"   # for importing local modules\n",
    "MASTER_CSV = \"/home/hch/opportunistic/20250518_master4_merged2.csv\"  # for eye_orientation merge\n",
    "\n",
    "# segmentation roots (same as your code)\n",
    "ARTERY_DIR = Path(\"/home/hch/opportunistic/AutoMorph_Data/Results/M2/artery_vein/artery_binary_process\")\n",
    "VEIN_DIR   = Path(\"/home/hch/opportunistic/AutoMorph_Data/Results/M2/artery_vein/vein_binary_process\")\n",
    "BINVES_DIR = Path(\"/home/hch/opportunistic/AutoMorph_Data/Results/M2/binary_vessel/binary_process\")  # optional\n",
    "ODC_RAW_DIR= Path(\"/home/hch/opportunistic/AutoMorph_Data/Results/M2/optic_disc_cup/raw\")\n",
    "\n",
    "# image size & batch\n",
    "IMG_SIZE   = 448\n",
    "BATCH      = 8\n",
    "\n",
    "# make paths consistent with existing codebase\n",
    "os.chdir(WORK_DIR)\n",
    "\n",
    "from data import DementiaDetectionDataset, DementiaPredictionDataset\n",
    "from models.encoder import build_model\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 0) Config: all combos\n",
    "# -----------------------------------------------------------------------------\n",
    "ARCHES = ['retfound', 'mae', 'openclip']\n",
    "FTS    = ['partial', 'lora']\n",
    "\n",
    "\n",
    "def ft_blks_for(ft: str):\n",
    "    if ft == 'partial':\n",
    "        return 4          \n",
    "    if ft == 'lora':\n",
    "        return 'full'     \n",
    "    return None           \n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Utilities: MODEL_DESC, CKPT/INFER paths, robust CSV threshold lookup\n",
    "# -----------------------------------------------------------------------------\n",
    "def model_desc_from_csv_row(row: pd.Series) -> str:\n",
    "    arch = str(row['arch'])\n",
    "    ft   = str(row['ft'])\n",
    "    desc = f\"{arch}_{ft}\"\n",
    "    if ft == 'partial':\n",
    "        desc += f\"_ft_{row['ft_blks']}\"\n",
    "    elif ft == 'lora':\n",
    "        lrk = str(row.get('lora_rank', ''))\n",
    "        desc += f\"_rank_{lrk}_ft_{row['ft_blks']}\"\n",
    "    return desc\n",
    "\n",
    "def model_desc_from_spec(arch: str, ft: str, lora_rank: str | int | None) -> str:\n",
    "    desc = f\"{arch}_{ft}\"\n",
    "    if ft == 'partial':\n",
    "        desc += f\"_ft_4\"\n",
    "    elif ft == 'lora':\n",
    "        lrk = str(lora_rank if lora_rank is not None else \"4\")  # default guess 4\n",
    "        desc += f\"_rank_{lrk}_ft_full\"\n",
    "    return desc\n",
    "\n",
    "def ckpt_path(desc: str) -> str:\n",
    "    return f\"/home/kjw/Projects/dementia/ckpts/{desc}/ckpt.pth.tar\"\n",
    "\n",
    "def infer_dir(desc: str) -> str:\n",
    "    return f\"/home/hch/dementia/infer_out/{desc}\"\n",
    "\n",
    "def tensors_dirs(desc: str) -> tuple[str, str]:\n",
    "    out_test   = f\"./tensors/{desc}_test\"\n",
    "    out_future = f\"./tensors/{desc}_future\"\n",
    "    os.makedirs(out_test, exist_ok=True)\n",
    "    os.makedirs(out_future, exist_ok=True)\n",
    "    return out_test, out_future\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Read thresholds: choose best match per (arch, ft, ft_blks) — for lora pick the row with max AUC if multiple ranks\n",
    "# -----------------------------------------------------------------------------\n",
    "THRESH_CSV = Path(\"./youden_thresholds.csv\")  # saved in root_dir by trainer.py\n",
    "if not THRESH_CSV.exists():\n",
    "    # 도중에 경로 달랐으면 여기 맞춰주세요\n",
    "    alt = Path(\"/home/hch/dementia/youden_thresholds.csv\")\n",
    "    if alt.exists():\n",
    "        THRESH_CSV = alt\n",
    "assert THRESH_CSV.exists(), f\"youden_thresholds.csv not found: {THRESH_CSV}\"\n",
    "\n",
    "thr_df = pd.read_csv(THRESH_CSV)\n",
    "# normalize columns to str for matching\n",
    "for col in [\"arch\",\"ft\",\"ft_blks\",\"split\"]:\n",
    "    if col in thr_df.columns:\n",
    "        thr_df[col] = thr_df[col].astype(str)\n",
    "\n",
    "# Filter only 'valid' split rows\n",
    "thr_df = thr_df.query(\"split == 'valid'\").copy()\n",
    "\n",
    "def pick_threshold_row(arch: str, ft: str) -> pd.Series | None:\n",
    "    ftb = ft_blks_for(ft)\n",
    "    df = thr_df.copy()\n",
    "    df = df.query(\"arch == @arch and ft == @ft\")\n",
    "    if ft == 'linear':\n",
    "        pass\n",
    "    elif ft == 'partial':\n",
    "        df = df.query(\"ft_blks == '4'\")\n",
    "    elif ft == 'lora':\n",
    "        df = df.query(\"ft_blks == 'full'\")\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    if 'auc' in df.columns:\n",
    "        df = df.sort_values('auc', ascending=False)\n",
    "    return df.iloc[0]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Model build & load\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_model_for(arch: str, ft: str, img_size: int = IMG_SIZE, enable_amp: bool = True, lora_rank=None):\n",
    "    args = type(\"Args\", (), {})()\n",
    "    args.arch = arch\n",
    "    args.ft   = ft\n",
    "    args.img_size = img_size\n",
    "\n",
    "    ftb = ft_blks_for(ft)\n",
    "    if ftb is not None:\n",
    "        args.ft_blks = ftb\n",
    "\n",
    "    if ft == 'partial' and isinstance(getattr(args, 'ft_blks', None), str):\n",
    "        args.ft_blks = int(args.ft_blks)\n",
    "\n",
    "    if ft == 'lora':\n",
    "        try:\n",
    "            args.lora_rank = int(lora_rank) if lora_rank is not None and str(lora_rank) != 'nan' else 4\n",
    "        except Exception:\n",
    "            args.lora_rank = 4\n",
    "\n",
    "    return build_model(args)\n",
    "\n",
    "def safe_load_state_dict(model, sd):\n",
    "    if isinstance(sd, dict):\n",
    "        for key in [\"state_dict\", \"model\", \"net\", \"module\", \"ema_state\"]:\n",
    "            if key in sd and isinstance(sd[key], dict):\n",
    "                try:\n",
    "                    model.load_state_dict(sd[key], strict=False)\n",
    "                    return True\n",
    "                except Exception:\n",
    "                    pass\n",
    "        try:\n",
    "            model.load_state_dict(sd, strict=False)\n",
    "            return True\n",
    "        except Exception:\n",
    "            pass\n",
    "    return False\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) ViT attention patch & Grad-CAM rollout (same as your code)\n",
    "# -----------------------------------------------------------------------------\n",
    "def find_vit_backbone(module: nn.Module):\n",
    "    if hasattr(module, \"blocks\"):\n",
    "        return module\n",
    "    for _, child in module.named_children():\n",
    "        vb = find_vit_backbone(child)\n",
    "        if vb is not None:\n",
    "            return vb\n",
    "    return None\n",
    "\n",
    "def patch_attention_to_capture(vit_module):\n",
    "    for blk in vit_module.blocks:\n",
    "        attn = blk.attn\n",
    "        if getattr(attn, \"_patched_capture\", False):\n",
    "            continue\n",
    "        def wrapped_forward(x, _attn=attn):\n",
    "            B, N, C = x.shape\n",
    "            qkv = _attn.qkv(x)\n",
    "            head_dim = C // _attn.num_heads\n",
    "            qkv = qkv.reshape(B, N, 3, _attn.num_heads, head_dim).permute(2,0,3,1,4)\n",
    "            q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "            if hasattr(_attn, \"q_norm\") and _attn.q_norm is not None:\n",
    "                q = _attn.q_norm(q.transpose(2,3)).transpose(2,3)\n",
    "            if hasattr(_attn, \"k_norm\") and _attn.k_norm is not None:\n",
    "                k = _attn.k_norm(k.transpose(2,3)).transpose(2,3)\n",
    "            scale = (head_dim ** -0.5)\n",
    "            q = q * scale\n",
    "            attn_scores = torch.matmul(q, k.transpose(-2, -1))   # [B,H,N,N]\n",
    "            attn_probs  = attn_scores.softmax(dim=-1)\n",
    "            _attn._last_attn = attn_probs\n",
    "            try:\n",
    "                _attn._last_attn.retain_grad()\n",
    "            except Exception:\n",
    "                pass\n",
    "            attn_probs = _attn.attn_drop(attn_probs)\n",
    "            x_out = torch.matmul(attn_probs, v)\n",
    "            x_out = x_out.transpose(1,2).reshape(B, N, C)\n",
    "            x_out = _attn.proj(x_out)\n",
    "            x_out = _attn.proj_drop(x_out)\n",
    "            return x_out\n",
    "        attn.forward = wrapped_forward\n",
    "        attn._patched_capture = True\n",
    "\n",
    "\n",
    "class ViTGradCamRollout:\n",
    "    def __init__(self, vit_module):\n",
    "        self.vit = vit_module\n",
    "\n",
    "    def _normalize_attn(self, M):\n",
    "        M = M / (M.sum(dim=-1, keepdim=True) + 1e-6)\n",
    "        T = M.size(-1)\n",
    "        M = M + torch.eye(T, device=M.device, dtype=M.dtype)\n",
    "        M = M / (M.sum(dim=-1, keepdim=True) + 1e-6)\n",
    "        return M\n",
    "\n",
    "    def compute_cam(self, model, img_tensor, class_idx=1):\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        out = model(img_tensor)\n",
    "        if isinstance(out, dict):\n",
    "            out = out.get(\"logits\", out.get(\"pred\", out))\n",
    "        if not torch.is_tensor(out):\n",
    "            out = torch.as_tensor(out)\n",
    "        if out.ndim == 1:\n",
    "            score = out[0]\n",
    "        elif out.ndim == 2 and out.shape[1] == 1:\n",
    "            score = out[0, 0]\n",
    "        elif out.ndim == 2 and out.shape[1] >= 2:\n",
    "            score = out[0, class_idx]\n",
    "        else:\n",
    "            score = out.reshape(-1)[0]\n",
    "        score.backward(retain_graph=False)\n",
    "\n",
    "        attn_list, grad_list = [], []\n",
    "        for blk in self.vit.blocks:\n",
    "            A = getattr(blk.attn, \"_last_attn\", None)\n",
    "            if A is None:\n",
    "                continue\n",
    "            attn_list.append(A)\n",
    "            grad_list.append(getattr(A, \"grad\", None))\n",
    "\n",
    "        if len(attn_list) == 0:\n",
    "            raise RuntimeError(\"No attention captured; check patching.\")\n",
    "\n",
    "        if hasattr(self.vit, \"patch_embed\") and hasattr(self.vit.patch_embed, \"grid_size\"):\n",
    "            gh, gw = self.vit.patch_embed.grid_size\n",
    "        else:\n",
    "            Ttok = attn_list[0].shape[-1]\n",
    "            n = Ttok - 1\n",
    "            s = int(math.isqrt(n))\n",
    "            gh = gw = s\n",
    "\n",
    "        rollout = None\n",
    "        for A, G in zip(attn_list, grad_list):\n",
    "            A = A[0].mean(dim=0).mean(dim=0)          # [T,T]\n",
    "            if G is not None:\n",
    "                G = G[0].mean(dim=0).mean(dim=0)      # [T,T]\n",
    "                M = (A * G).clamp(min=0)\n",
    "            else:\n",
    "                M = A.clamp(min=0)\n",
    "            M = self._normalize_attn(M)\n",
    "            rollout = M if rollout is None else torch.matmul(rollout, M)\n",
    "\n",
    "        cls_to_patches = rollout[0, 1:].detach().cpu().numpy()\n",
    "        cam = cls_to_patches.reshape(gh, gw)\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-6)\n",
    "        return cam\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Dataset + meta join & TP filtering\n",
    "# -----------------------------------------------------------------------------\n",
    "def try_get_df_row(ds, idx):\n",
    "    for attr in [\"df\", \"meta\", \"ann\", \"items\", \"data\"]:\n",
    "        if hasattr(ds, attr):\n",
    "            obj = getattr(ds, attr)\n",
    "            if hasattr(obj, \"iloc\"):\n",
    "                return obj.iloc[idx]\n",
    "            if isinstance(obj, (list, tuple)) and len(obj) > idx:\n",
    "                return obj[idx]\n",
    "    return None\n",
    "\n",
    "def extract_path(row):\n",
    "    for c in [\"pngfilename\", \"img_path\", \"filepath\", \"path\"]:\n",
    "        if row is not None and (c in row):\n",
    "            return row[c]\n",
    "    return None\n",
    "\n",
    "def attach_imgpath(df_csv, ds):\n",
    "    rows = []\n",
    "    for _, r in df_csv.iterrows():\n",
    "        meta = try_get_df_row(ds, int(r[\"idx\"]))\n",
    "        img = extract_path(meta)\n",
    "        rows.append({**r.to_dict(), \"img_path\": img})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def normalize_master(master_csv: str = MASTER_CSV) -> pd.DataFrame:\n",
    "    ddd = pd.read_csv(master_csv)\n",
    "    ddd['pngfilename'] = ddd['pngfilename'].str.replace('.', '_', regex=False)\n",
    "    ddd['pngfilename'] = ddd['pngfilename'].str.replace('_png', '.png', regex=False)\n",
    "    ddd['img_path'] = '/home/hch/opportunistic/AutoMorph_Data/Results/M0/images/' + ddd['pngfilename']\n",
    "    return ddd[['img_path','eye_orientation','pngfilename']]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) Export tensors (origin_images.pth & saliency_map.pth)\n",
    "# -----------------------------------------------------------------------------\n",
    "preprocess = Compose([Resize((IMG_SIZE, IMG_SIZE)), ToTensor()])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_tensor_01(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    t = preprocess(img)  # [3,H,W], 0..1\n",
    "    return t\n",
    "\n",
    "def ensure_path(p):\n",
    "    if p and os.path.isabs(p):\n",
    "        return p\n",
    "    return os.path.join(WORK_DIR, p) if isinstance(p, str) else None\n",
    "\n",
    "def compute_cam_tensor(rollout, model, img_path):\n",
    "    full = ensure_path(img_path)\n",
    "    if (not full) or (not os.path.exists(full)):\n",
    "        return None, None\n",
    "    x = load_tensor_01(full).unsqueeze(0).to(device, non_blocking=True)  # [1,3,H,W]\n",
    "    cam_hw = rollout.compute_cam(model, x, class_idx=1)                  # [h',w'] in [0,1]\n",
    "    cam_hw = cv2.resize((cam_hw*255).astype(np.uint8), (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "    cam_hw = torch.from_numpy(cam_hw).float().div(255.0)                 # [H,W] in [0,1]\n",
    "    return x.squeeze(0).cpu(), cam_hw.unsqueeze(0)                       # [3,H,W], [1,H,W]\n",
    "\n",
    "def export_tp_pack(tp_df: pd.DataFrame, out_dir: str, rollout: ViTGradCamRollout, model: nn.Module):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    ori_list, cam_list, meta_list = [], [], []\n",
    "    for _, row in tqdm(tp_df.iterrows(), total=len(tp_df), desc=f\"Export {Path(out_dir).name}\"):\n",
    "        p = row[\"img_path\"]\n",
    "        ori, cam = compute_cam_tensor(rollout, model, p)\n",
    "        if ori is None:\n",
    "            continue\n",
    "        ori_list.append(ori.unsqueeze(0))  # [1,3,H,W]\n",
    "        cam_list.append(cam.unsqueeze(0))  # [1,1,H,W]\n",
    "        meta_list.append({\n",
    "            \"idx\": int(row[\"idx\"]),\n",
    "            \"img_path\": ensure_path(p),\n",
    "            \"eye_orientation\": row.get(\"eye_orientation\", None),\n",
    "            \"pred\": float(row[\"pred\"]),\n",
    "            \"label_or_event\": int(row.get(\"label\", row.get(\"event\", -1)))\n",
    "        })\n",
    "    if len(ori_list) == 0:\n",
    "        print(\"No TP images to export:\", out_dir); return False\n",
    "    origin_images = torch.cat(ori_list, dim=0)        # [N,3,H,W]\n",
    "    saliency_map  = torch.cat(cam_list, dim=0)        # [N,1,H,W]\n",
    "    torch.save(origin_images.contiguous(), os.path.join(out_dir, \"origin_images.pth\"))\n",
    "    torch.save(saliency_map.contiguous(),  os.path.join(out_dir, \"saliency_map.pth\"))\n",
    "    with open(os.path.join(out_dir, \"meta.json\"), \"w\") as f:\n",
    "        json.dump(meta_list, f, indent=2)\n",
    "    print(f\"[✓] Saved: {out_dir}/origin_images.pth, saliency_map.pth  (N={len(meta_list)})\")\n",
    "    return True\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7) Rep Grad-CAM L/R overlay (same as your code)\n",
    "# -----------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "REP_ROOT = Path(\"./rep_gradcam_lr\")\n",
    "REP_ROOT.mkdir(exist_ok=True)\n",
    "\n",
    "def _to_numpy_img(t3chw: torch.Tensor):\n",
    "    return t3chw.detach().cpu().clamp(0,1).permute(1,2,0).numpy()\n",
    "\n",
    "def _overlay_cam(rgb_hw3, cam_hw, alpha=0.45, cmap_name=\"jet\"):\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "    cam_rgb = cmap(cam_hw)[..., :3]\n",
    "    out = (1 - alpha) * rgb_hw3 + alpha * cam_rgb\n",
    "    return np.clip(out, 0, 1)\n",
    "\n",
    "def _norm_eye_label(x):\n",
    "    if x is None: return None\n",
    "    s = str(x).strip().lower()\n",
    "    if s in [\"r\",\"right\",\"rt\",\"오\",\"오른\",\"오른쪽\",\"1\",\"true\",\"od\",\"o.d\"]:\n",
    "        return \"R\"\n",
    "    if s in [\"l\",\"left\",\"lt\",\"왼\",\"왼쪽\",\"0\",\"false\",\"os\",\"o.s\"]:\n",
    "        return \"L\"\n",
    "    try:\n",
    "        return \"R\" if int(float(s)) == 1 else \"L\"\n",
    "    except: return None\n",
    "\n",
    "def _load_pack(src_dir: str):\n",
    "    p = Path(src_dir)\n",
    "    ori = torch.load(p/\"origin_images.pth\")\n",
    "    cam = torch.load(p/\"saliency_map.pth\")\n",
    "    with open(p/\"meta.json\",\"r\") as f:\n",
    "        metas = json.load(f)\n",
    "    return ori, cam, metas\n",
    "\n",
    "def _indices_by_eye(metas, eye_code):\n",
    "    return [i for i,m in enumerate(metas) if _norm_eye_label(m.get(\"eye_orientation\")) == eye_code]\n",
    "\n",
    "def _avg_heatmap(cam: torch.Tensor, indices):\n",
    "    if not indices: return None\n",
    "    arr = cam[indices,0].detach().cpu().numpy()\n",
    "    mean = arr.mean(axis=0)\n",
    "    mn,mx = mean.min(), mean.max()\n",
    "    if mx > mn: mean = (mean - mn)/(mx - mn)\n",
    "    return mean\n",
    "\n",
    "def _random_from(indices, seed=None):\n",
    "    if not indices: return None\n",
    "    rng = random.Random(seed)\n",
    "    return rng.choice(indices)\n",
    "\n",
    "def _save_img(array_hw3, fname, out_dir: Path):\n",
    "    out_dir.mkdir(exist_ok=True, parents=True)\n",
    "    plt.imsave(out_dir / fname, array_hw3); print(f\"[✓] Saved: {out_dir/fname}\")\n",
    "\n",
    "def _save_heatmap(array_hw, fname, out_dir: Path, cmap=\"jet\"):\n",
    "    out_dir.mkdir(exist_ok=True, parents=True)\n",
    "    plt.imsave(out_dir / fname, array_hw, cmap=cmap); print(f\"[✓] Saved: {out_dir/fname}\")\n",
    "\n",
    "def save_heatmap_and_overlay(src_dir: str, model_desc: str, set_name=\"TEST\", seed=0, cmap=\"jet\"):\n",
    "    ori, cam, metas = _load_pack(src_dir)\n",
    "    idxs_L = _indices_by_eye(metas, \"L\")\n",
    "    idxs_R = _indices_by_eye(metas, \"R\")\n",
    "    avg_L = _avg_heatmap(cam, idxs_L)\n",
    "    avg_R = _avg_heatmap(cam, idxs_R)\n",
    "    rL = _random_from(idxs_L, seed)\n",
    "    rR = _random_from(idxs_R, seed+1)\n",
    "\n",
    "    out_dir = REP_ROOT / model_desc\n",
    "    if avg_L is not None:\n",
    "        _save_heatmap(avg_L, f\"{set_name}_Left_heatmap.png\", out_dir, cmap)\n",
    "        if rL is not None:\n",
    "            overlay_L = _overlay_cam(_to_numpy_img(ori[rL]), avg_L, alpha=0.45, cmap_name=cmap)\n",
    "            _save_img(overlay_L, f\"{set_name}_Left_overlay.png\", out_dir)\n",
    "    if avg_R is not None:\n",
    "        _save_heatmap(avg_R, f\"{set_name}_Right_heatmap.png\", out_dir, cmap)\n",
    "        if rR is not None:\n",
    "            overlay_R = _overlay_cam(_to_numpy_img(ori[rR]), avg_R, alpha=0.45, cmap_name=cmap)\n",
    "            _save_img(overlay_R, f\"{set_name}_Right_overlay.png\", out_dir)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8) Mask utilities + attention summaries (ODC split into 4 wedges added)\n",
    "# -----------------------------------------------------------------------------\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "def ensure_bool_mask(mask_img: Image.Image, size=(IMG_SIZE, IMG_SIZE)) -> torch.Tensor:\n",
    "    if not isinstance(mask_img, Image.Image):\n",
    "        mask_img = Image.fromarray(np.asarray(mask_img))\n",
    "    mask = mask_img.resize(size, resample=Image.NEAREST)\n",
    "    mask_np = np.array(mask)\n",
    "    mask_bin = (mask_np > 0).astype(np.uint8)\n",
    "    return torch.from_numpy(mask_bin)\n",
    "\n",
    "def load_mask_by_filename(root: Path, pngfilename: str) -> torch.Tensor | None:\n",
    "    cand = root / pngfilename\n",
    "    if cand.exists():\n",
    "        return ensure_bool_mask(Image.open(cand))\n",
    "    stem = Path(pngfilename).stem\n",
    "    for ext in (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\"):\n",
    "        p = root / f\"{stem}{ext}\"\n",
    "        if p.exists():\n",
    "            return ensure_bool_mask(Image.open(p))\n",
    "    return None\n",
    "\n",
    "def load_optic_disc_cup_union(pngfilename: str) -> torch.Tensor | None:\n",
    "    p = ODC_RAW_DIR / pngfilename\n",
    "    if not p.exists():\n",
    "        stem = Path(pngfilename).stem\n",
    "        found = None\n",
    "        for ext in (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\"):\n",
    "            cand = ODC_RAW_DIR / f\"{stem}{ext}\"\n",
    "            if cand.exists():\n",
    "                found = cand\n",
    "                break\n",
    "        if found is None:\n",
    "            return None\n",
    "        p = found\n",
    "    try:\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        arr = np.array(img)\n",
    "        r = arr[..., 0]\n",
    "        b = arr[..., 2]\n",
    "        rb_union = ((r > 0) | (b > 0)).astype(np.uint8)\n",
    "        return ensure_bool_mask(Image.fromarray(rb_union * 255))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def split_odc_quadrants(odc: torch.Tensor):\n",
    "\n",
    "    if odc is None or odc.ndim != 2:\n",
    "        return None\n",
    "    h, w = odc.shape\n",
    "    ys, xs = torch.nonzero(odc > 0, as_tuple=True)\n",
    "    if ys.numel() == 0:\n",
    "        return None\n",
    "\n",
    "    cy = ys.float().mean()\n",
    "    cx = xs.float().mean()\n",
    "\n",
    "    yy = torch.arange(h, device=odc.device).view(-1, 1).expand(h, w).float()\n",
    "    xx = torch.arange(w, device=odc.device).view(1, -1).expand(h, w).float()\n",
    "\n",
    "    # 두 대각선: y-cy =  (x-cx),  y-cy = -(x-cx)\n",
    "    sign1 = (yy - cy) - (xx - cx)   # <0 / >0\n",
    "    sign2 = (yy - cy) + (xx - cx)   # <0 / >0\n",
    "\n",
    "    superior = ((sign1 < 0) & (sign2 < 0) & (odc > 0)).to(torch.uint8)\n",
    "    inferior = ((sign1 > 0) & (sign2 > 0) & (odc > 0)).to(torch.uint8)\n",
    "    right_w  = ((sign1 < 0) & (sign2 > 0) & (odc > 0)).to(torch.uint8)\n",
    "    left_w   = ((sign1 > 0) & (sign2 < 0) & (odc > 0)).to(torch.uint8)\n",
    "\n",
    "    return {\n",
    "        \"superior\": superior,\n",
    "        \"inferior\": inferior,\n",
    "        \"right\": right_w,\n",
    "        \"left\": left_w,\n",
    "        \"cx\": float(cx.item()),\n",
    "        \"cy\": float(cy.item()),\n",
    "    }\n",
    "\n",
    "def make_fov_mask(h=IMG_SIZE, w=IMG_SIZE) -> torch.Tensor:\n",
    "    yy, xx = np.ogrid[:h, :w]\n",
    "    cy, cx = h // 2, w // 2\n",
    "    r = min(h, w) // 2\n",
    "    fov = (yy - cy)**2 + (xx - cx)**2 <= (r**2)\n",
    "    return torch.from_numpy(fov.astype(np.uint8))\n",
    "\n",
    "def normalize_gradcam_into_fov(gradcam_t: torch.Tensor, fov_mask: torch.Tensor) -> torch.Tensor | None:\n",
    "    if gradcam_t.dim() == 3:\n",
    "        if gradcam_t.size(0) in (1,3):\n",
    "            gradcam_t = gradcam_t[0, ...] if gradcam_t.size(0) > 0 else gradcam_t.squeeze(0)\n",
    "        else:\n",
    "            gradcam_t = gradcam_t.squeeze(0)\n",
    "    elif gradcam_t.dim() == 4:\n",
    "        gradcam_t = gradcam_t.squeeze()\n",
    "    gc = TF.to_pil_image(gradcam_t.float())\n",
    "    gc = gc.resize((IMG_SIZE, IMG_SIZE), resample=Image.BILINEAR)\n",
    "    gc = TF.pil_to_tensor(gc).squeeze().float()\n",
    "    gc = gc * fov_mask\n",
    "    s = gc.sum().item()\n",
    "    if s <= 0:\n",
    "        return None\n",
    "    gc = 100.0 * gc / s\n",
    "    return gc\n",
    "\n",
    "def region_mean(gc_norm100: torch.Tensor, region_mask01: torch.Tensor) -> float:\n",
    "    denom = region_mask01.sum().item()\n",
    "    if denom <= 0: return float(\"nan\")\n",
    "    return (gc_norm100 * region_mask01).sum().item() / denom\n",
    "\n",
    "def compute_metrics_for_dataset(df_csv: Path, saliency_pth: Path, out_dir: Path) -> pd.DataFrame:\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.read_csv(df_csv)\n",
    "    if \"pngfilename\" not in df.columns:\n",
    "        raise ValueError(f\"'pngfilename' column not found in {df_csv}\")\n",
    "    gradcams = torch.load(saliency_pth)\n",
    "    n = len(gradcams) if hasattr(gradcams, \"__len__\") else int(gradcams.size(0))\n",
    "    df = df.reset_index(drop=True)\n",
    "    if len(df) != n:\n",
    "        m = min(len(df), n)\n",
    "        df = df.iloc[:m].reset_index(drop=True)\n",
    "        if hasattr(gradcams, \"__len__\"):\n",
    "            gradcams = gradcams[:m]\n",
    "        else:\n",
    "            gradcams = gradcams[:m, ...]\n",
    "    records = []\n",
    "    fov = make_fov_mask()\n",
    "    for idx in tqdm(range(len(df)), desc=f\"Computing masks for {df_csv.stem}\", total=len(df)):\n",
    "        row = df.iloc[idx]\n",
    "        pngfilename = str(row[\"pngfilename\"])\n",
    "        artery = load_mask_by_filename(ARTERY_DIR, pngfilename)\n",
    "        vein   = load_mask_by_filename(VEIN_DIR,   pngfilename)\n",
    "        if artery is None or vein is None:\n",
    "            continue\n",
    "        odc = load_optic_disc_cup_union(pngfilename)  # may be None\n",
    "        both = (artery | vein).clamp_(0, 1)\n",
    "        not_both = ((1 - both) * fov).clamp_(0, 1)\n",
    "        if odc is not None:\n",
    "            odc = (odc * fov).clamp_(0, 1)\n",
    "            not_odc = ((1 - odc) * fov).clamp_(0, 1)\n",
    "            not_odc_not_both = ((1 - ((both | odc).clamp_(0, 1))) * fov).clamp_(0, 1)\n",
    "            quads = split_odc_quadrants(odc)\n",
    "        else:\n",
    "            not_odc = None; not_odc_not_both = None; quads = None\n",
    "\n",
    "        gc = normalize_gradcam_into_fov(gradcams[idx], fov)\n",
    "        if gc is None:\n",
    "            continue\n",
    "\n",
    "        vein_ = (vein * fov).clamp_(0, 1);    not_vein = ((1 - vein) * fov).clamp_(0, 1)\n",
    "        artery_ = (artery * fov).clamp_(0, 1);not_artery = ((1 - artery) * fov).clamp_(0, 1)\n",
    "        both_   = (both * fov).clamp_(0, 1);  not_both_ = not_both\n",
    "\n",
    "        eye_code = _norm_eye_label(row.get(\"eye_orientation\", None))\n",
    "\n",
    "        od_temporal = float(\"nan\")\n",
    "        od_nasal    = float(\"nan\")\n",
    "        od_sup      = float(\"nan\")\n",
    "        od_inf      = float(\"nan\")\n",
    "\n",
    "        if (gc is not None) and (quads is not None):\n",
    "            # superior / inferior\n",
    "            od_sup = region_mean(gc, quads[\"superior\"])\n",
    "            od_inf = region_mean(gc, quads[\"inferior\"])\n",
    "\n",
    "            # temporal / nasal \n",
    "            if eye_code == \"L\":\n",
    "                temporal_mask = quads[\"right\"]\n",
    "                nasal_mask    = quads[\"left\"]\n",
    "            elif eye_code == \"R\":\n",
    "                temporal_mask = quads[\"left\"]\n",
    "                nasal_mask    = quads[\"right\"]\n",
    "            else:\n",
    "                temporal_mask = None\n",
    "                nasal_mask    = None\n",
    "\n",
    "            if temporal_mask is not None:\n",
    "                od_temporal = region_mean(gc, temporal_mask)\n",
    "            if nasal_mask is not None:\n",
    "                od_nasal = region_mean(gc, nasal_mask)\n",
    "\n",
    "        result = {\n",
    "            \"pngfilename\": pngfilename,\n",
    "            \"veins_n\":               region_mean(gc, vein_),\n",
    "            \"not_veins_n\":           region_mean(gc, not_vein),\n",
    "            \"arteries_n\":            region_mean(gc, artery_),\n",
    "            \"not_arteries_n\":        region_mean(gc, not_artery),\n",
    "            \"both_n\":                region_mean(gc, both_),\n",
    "            \"not_both_n\":            region_mean(gc, not_both_),\n",
    "            \"has_optic_disc\":        bool(odc is not None),\n",
    "            \"optic_disc_n\":          float(\"nan\") if odc is None else region_mean(gc, odc),\n",
    "            \"not_optic_disc_n\":      float(\"nan\") if odc is None else region_mean(gc, not_odc),\n",
    "            \"not_optic_disc_not_both_n\": float(\"nan\") if odc is None else region_mean(gc, not_odc_not_both),\n",
    "            \"optic_disc_temporal_n\": od_temporal,\n",
    "            \"optic_disc_nasal_n\":    od_nasal,\n",
    "            \"optic_disc_superior_n\": od_sup,\n",
    "            \"optic_disc_inferior_n\": od_inf,\n",
    "        }\n",
    "        records.append(result)\n",
    "    res = pd.DataFrame.from_records(records)\n",
    "    out_csv = out_dir / f\"RESULTS_{df_csv.stem.replace('_df','')}.csv\"\n",
    "    res.to_csv(out_csv, index=False)\n",
    "    print(f\"[Saved] {out_csv}  (n={len(res)})\")\n",
    "    if len(res):\n",
    "        cols = [\"veins_n\",\"not_veins_n\",\"arteries_n\",\"not_arteries_n\",\"both_n\",\"not_both_n\",\n",
    "                \"optic_disc_n\",\"not_optic_disc_n\",\"not_optic_disc_not_both_n\",\n",
    "                \"optic_disc_temporal_n\",\"optic_disc_nasal_n\",\"optic_disc_superior_n\",\"optic_disc_inferior_n\"]\n",
    "        summary = res[cols].mean(numeric_only=True)\n",
    "        print(\"Column means:\\n\", summary.to_string())\n",
    "    return res\n",
    "\n",
    "def _safe_ratio(num: pd.Series, den: pd.Series) -> pd.Series:\n",
    "    num = pd.to_numeric(num, errors=\"coerce\"); den = pd.to_numeric(den, errors=\"coerce\")\n",
    "    ratio = num / den\n",
    "    ratio[(~np.isfinite(den)) | (den <= 0)] = np.nan\n",
    "    return ratio\n",
    "\n",
    "def bootstrap_ci(data: np.ndarray, n_boot: int = 2000, ci: int = 95, seed: int = 42):\n",
    "    data = np.asarray(data); data = data[np.isfinite(data)]\n",
    "    if data.size == 0: return (np.nan, np.nan)\n",
    "    rng = np.random.default_rng(seed); means = np.empty(n_boot); n = data.size\n",
    "    for i in range(n_boot):\n",
    "        sample = rng.choice(data, size=n, replace=True)\n",
    "        means[i] = np.nanmean(sample)\n",
    "    alpha = (100 - ci) / 2.0\n",
    "    lower = np.percentile(means, alpha); upper = np.percentile(means, 100 - alpha)\n",
    "    return (lower, upper)\n",
    "\n",
    "def summarize_attention(res_df: pd.DataFrame, label: str = \"TEST\", n_boot: int = 2000) -> pd.DataFrame:\n",
    "    ref = res_df[\"not_optic_disc_not_both_n\"]\n",
    "    ratios = pd.DataFrame({\n",
    "        \"vascular_attention_vein\":   _safe_ratio(res_df[\"veins_n\"],        ref),\n",
    "        \"vascular_attention_artery\": _safe_ratio(res_df[\"arteries_n\"],      ref),\n",
    "        \"vascular_attention_both\":   _safe_ratio(res_df[\"both_n\"],          ref),\n",
    "        \"optic_disc_attention\":      _safe_ratio(res_df[\"optic_disc_n\"],    ref),\n",
    "\n",
    "        \"optic_disc_attention_temporal\": _safe_ratio(res_df[\"optic_disc_temporal_n\"], ref),\n",
    "        \"optic_disc_attention_nasal\":    _safe_ratio(res_df[\"optic_disc_nasal_n\"],     ref),\n",
    "        \"optic_disc_attention_superior\": _safe_ratio(res_df[\"optic_disc_superior_n\"],  ref),\n",
    "        \"optic_disc_attention_inferior\": _safe_ratio(res_df[\"optic_disc_inferior_n\"],  ref),\n",
    "    })\n",
    "    mean_vals = ratios.mean(numeric_only=True)\n",
    "    results = {}\n",
    "    for col in ratios.columns:\n",
    "        ci_low, ci_high = bootstrap_ci(ratios[col].values, n_boot=n_boot, ci=95)\n",
    "        results[col] = {\n",
    "            \"mean\": float(mean_vals[col]),\n",
    "            \"95%_CI_low\": float(ci_low),\n",
    "            \"95%_CI_high\": float(ci_high),\n",
    "            \"n_used\": int(np.isfinite(ratios[col].values).sum())\n",
    "        }\n",
    "    out = pd.DataFrame(results).T\n",
    "    print(f\"\\n=== [{label}] Attention ratios (ref = not_optic_disc_not_both_n) ===\")\n",
    "    print(mean_vals.to_string())\n",
    "    return ratios, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c27f4d-4fa7-4f4b-b527-8c25e3125c07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 9) MAIN LOOP over all combos\n",
    "# -----------------------------------------------------------------------------\n",
    "master_norm = normalize_master(MASTER_CSV)\n",
    "\n",
    "skip_n = 0  # 처음 2개 조합만 스킵\n",
    "count = 0\n",
    "\n",
    "for arch in ARCHES:\n",
    "    for ft in FTS:\n",
    "        if count < skip_n:\n",
    "            print(f\"[SKIP {count+1}/{skip_n}] arch={arch}, ft={ft}\")\n",
    "            count += 1\n",
    "            continue\n",
    "        \n",
    "        row = pick_threshold_row(arch, ft)\n",
    "        if row is None:\n",
    "            print(f\"[SKIP] No threshold row in youden_thresholds.csv for: arch={arch}, ft={ft}\")\n",
    "            continue\n",
    "\n",
    "        # derive model_desc from the selected row (captures lora_rank if present)\n",
    "        desc = model_desc_from_csv_row(row)\n",
    "\n",
    "        # re-check ft_blks policy to ensure alignment with requested mapping\n",
    "        if ft == 'partial' and str(row['ft_blks']) != '4':\n",
    "            print(f\"[SKIP] Found threshold with ft_blks={row['ft_blks']} but need 4: {arch}|{ft}\")\n",
    "            continue\n",
    "        if ft == 'lora' and str(row['ft_blks']) != 'full':\n",
    "            print(f\"[SKIP] Found threshold with ft_blks={row['ft_blks']} but need full: {arch}|{ft}\")\n",
    "            continue\n",
    "\n",
    "        BEST_THRESH = float(row['youden_thr'])\n",
    "        AUC_USED    = float(row.get('auc', float('nan')))\n",
    "        LORA_RANK   = row.get('lora_rank', None)\n",
    "\n",
    "        ckpt = ckpt_path(desc)\n",
    "        infer = infer_dir(desc)\n",
    "        OUT_ROOT_TEST, OUT_ROOT_FUTURE = tensors_dirs(desc)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"[{desc}]  arch={arch}  ft={ft}  ft_blks={row['ft_blks']}  lora_rank={LORA_RANK}  AUC={AUC_USED:.3f}\")\n",
    "        print(f\"  THRESH={BEST_THRESH:.6f}\")\n",
    "        print(f\"  CKPT  : {ckpt}\")\n",
    "        print(f\"  INFER : {infer}\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        # ---- Build & load model\n",
    "        model = build_model_for(arch, ft, IMG_SIZE, enable_amp=True, lora_rank=LORA_RANK).to(device).eval()\n",
    "        sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "        ok = safe_load_state_dict(model, sd)\n",
    "        if not ok:\n",
    "            print(f\"[SKIP] Failed to load weights from: {ckpt}\")\n",
    "            continue\n",
    "\n",
    "        # ---- Patch attention & rollout\n",
    "        vit = find_vit_backbone(model)\n",
    "        if vit is None:\n",
    "            print(f\"[SKIP] ViT backbone with 'blocks' not found in model: {desc}\")\n",
    "            continue\n",
    "        patch_attention_to_capture(vit)\n",
    "        rollout = ViTGradCamRollout(vit)\n",
    "\n",
    "        # ---- Load datasets & infer CSVs\n",
    "        test_ds = DementiaDetectionDataset(kind=\"test\", img_sz=IMG_SIZE)\n",
    "        fut_ds  = DementiaPredictionDataset(img_sz=IMG_SIZE)\n",
    "\n",
    "        test_csv = Path(infer) / \"test_preds.csv\"          # [idx, label, pred]\n",
    "        fut_csv  = Path(infer) / \"prediction_preds.csv\"    # [idx, pred, event, obs_time]\n",
    "        if not test_csv.exists() or not fut_csv.exists():\n",
    "            print(f\"[SKIP] Missing infer CSVs under {infer}\")\n",
    "            continue\n",
    "        test_csv = pd.read_csv(test_csv)\n",
    "        fut_csv  = pd.read_csv(fut_csv)\n",
    "\n",
    "        # ---- attach image paths\n",
    "        test_df = attach_imgpath(test_csv, test_ds)\n",
    "        fut_df  = attach_imgpath(fut_csv,  fut_ds)\n",
    "\n",
    "        # ---- merge eye_orientation\n",
    "        test_df = pd.merge(test_df, master_norm, on='img_path', how='inner')\n",
    "        fut_df  = pd.merge(fut_df,  master_norm, on='img_path', how='inner')\n",
    "\n",
    "        # ---- filter TP by BEST_THRESH\n",
    "        test_tp = test_df.query(\"pred >= @BEST_THRESH and label == 1\").reset_index(drop=True)\n",
    "        fut_tp  = fut_df .query(\"pred >= @BEST_THRESH and event == 1\").reset_index(drop=True)\n",
    "        print(f\"TP counts — TEST: {len(test_tp)} | FUTURE: {len(fut_tp)}\")\n",
    "\n",
    "        # ---- export origin_images.pth & saliency_map.pth\n",
    "        ok_test = export_tp_pack(test_tp, OUT_ROOT_TEST, rollout, model)\n",
    "        ok_fut  = export_tp_pack(fut_tp,  OUT_ROOT_FUTURE, rollout, model)\n",
    "\n",
    "        # ---- save the TP CSVs (like the base code)\n",
    "        if len(test_tp): test_tp.to_csv(Path(OUT_ROOT_TEST)/\"test_df.csv\", index=False)\n",
    "        if len(fut_tp):  fut_tp.to_csv(Path(OUT_ROOT_FUTURE)/\"fut_df.csv\", index=False)\n",
    "\n",
    "        # ---- representative Grad-CAM images (L/R heatmap & overlay)\n",
    "        if ok_test:   save_heatmap_and_overlay(OUT_ROOT_TEST,   desc, set_name=\"TEST\",   seed=123)\n",
    "        if ok_fut:    save_heatmap_and_overlay(OUT_ROOT_FUTURE, desc, set_name=\"FUTURE\", seed=456)\n",
    "\n",
    "        # ---- Mask metrics + Attention summaries\n",
    "        if ok_test:\n",
    "            test_df_csv   = Path(OUT_ROOT_TEST) / \"test_df.csv\"\n",
    "            test_saliency = Path(OUT_ROOT_TEST) / \"saliency_map.pth\"\n",
    "            test_out_dir  = Path(OUT_ROOT_TEST) / \"Mask\"\n",
    "            test_results  = compute_metrics_for_dataset(test_df_csv, test_saliency, test_out_dir)\n",
    "            test_ratios, test_summary = summarize_attention(test_results, label=f\"TEST:{desc}\", n_boot=2000)\n",
    "            test_summary.to_csv(test_out_dir / \"ATTN_summary_TEST.csv\")\n",
    "        if ok_fut:\n",
    "            fut_df_csv   = Path(OUT_ROOT_FUTURE) / \"fut_df.csv\"\n",
    "            fut_saliency = Path(OUT_ROOT_FUTURE) / \"saliency_map.pth\"\n",
    "            fut_out_dir  = Path(OUT_ROOT_FUTURE) / \"Mask\"\n",
    "            fut_results  = compute_metrics_for_dataset(fut_df_csv, fut_saliency, fut_out_dir)\n",
    "            fut_ratios,  fut_summary  = summarize_attention(fut_results,  label=f\"FUTURE:{desc}\", n_boot=2000)\n",
    "            fut_summary.to_csv(fut_out_dir / \"ATTN_summary_FUTURE.csv\")\n",
    "\n",
    "print(\"\\n✅ Done for all available combos with thresholds resolved from youden_thresholds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f0ee23-4f0a-46c3-929a-520dc2c38e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# Build nicely formatted tables from saved ATTN_summary files\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "ROOT = Path(\".\")\n",
    "\n",
    "def glob_summaries(kind: str):\n",
    "    # kind: \"TEST\" (detection), \"FUTURE\" (prediction)\n",
    "    if kind == \"TEST\":\n",
    "        pattern = \"tensors/*_test/Mask/ATTN_summary_TEST.csv\"\n",
    "    else:\n",
    "        pattern = \"tensors/*_future/Mask/ATTN_summary_FUTURE.csv\"\n",
    "    return sorted([Path(p) for p in ROOT.glob(pattern)])\n",
    "\n",
    "def parse_model_and_ft(desc: str):\n",
    "    arch_map = {\n",
    "        \"retfound\": \"RETFound\",\n",
    "        \"mae\": \"MAE\",\n",
    "        \"openclip\": \"OpenCLIP\",\n",
    "        \"dinov2\": \"DINOv2\",\n",
    "        \"dinov3\": \"DINOv3\",\n",
    "        \"retfound_dinov2\": \"RETFound_dinov2\",\n",
    "    }\n",
    "    d = desc.lower()\n",
    "    arch = None\n",
    "    for k in arch_map.keys():\n",
    "        if d.startswith(k):\n",
    "            arch = k\n",
    "            break\n",
    "    if desc.startswith(\"retfound_dinov2\"):\n",
    "        model = arch_map.get(\"retfound_dinov2\", \"RETFound_dinov2\")\n",
    "    else:\n",
    "        base_name = desc.split(\"_\")[0].upper() if arch is None else arch.upper()\n",
    "        model = arch_map.get(arch, base_name)\n",
    "        \n",
    "    if \"_partial_ft_4\" in d:\n",
    "        ft_method = \"partial_ft4\"\n",
    "    elif \"_lora_\" in d and \"_ft_full\" in d:\n",
    "        m = re.search(r\"lora_rank_(\\d+)_ft_full\", d)\n",
    "        ft_method = f\"lora_full(r{m.group(1)})\" if m else \"lora_full\"\n",
    "    else:\n",
    "        ft_method = \"linear\"\n",
    "    return model, ft_method\n",
    "\n",
    "def format_ci(mean, low, high):\n",
    "    def r2(x):\n",
    "        try: return f\"{float(x):.2f}\"\n",
    "        except: return \"nan\"\n",
    "    return f\"{r2(mean)} ({r2(low)} - {r2(high)})\"\n",
    "\n",
    "def one_row_from_summary(path: Path):\n",
    "    parent = path.parent.parent  # .../{MODEL_DESC}_{test|future}/Mask\n",
    "    desc_dir = parent.name       # ex) retfound_partial_ft_4_test\n",
    "    if desc_dir.endswith(\"_test\"):\n",
    "        desc = desc_dir[:-5]\n",
    "    elif desc_dir.endswith(\"_future\"):\n",
    "        desc = desc_dir[:-7]\n",
    "    else:\n",
    "        desc = desc_dir\n",
    "\n",
    "    model, ft_method = parse_model_and_ft(desc)\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "\n",
    "    def get_fmt(row_name):\n",
    "        if (row_name not in df.index) or any(col not in df.columns for col in [\"mean\",\"95%_CI_low\",\"95%_CI_high\"]):\n",
    "            return \"nan (nan - nan)\"\n",
    "        m  = df.loc[row_name, \"mean\"]\n",
    "        lo = df.loc[row_name, \"95%_CI_low\"]\n",
    "        hi = df.loc[row_name, \"95%_CI_high\"]\n",
    "        return format_ci(m, lo, hi)\n",
    "\n",
    "    row = {\n",
    "        \"Model\": model,\n",
    "        \"Finetuning Method\": ft_method,\n",
    "        \"Non-(vessel or optic disc)\": \"1.00 (reference)\",\n",
    "        \"Artery\": get_fmt(\"vascular_attention_artery\"),\n",
    "        \"Vein\": get_fmt(\"vascular_attention_vein\"),\n",
    "        \"Vessel (Artery + Vein)\": get_fmt(\"vascular_attention_both\"),\n",
    "        \"Optic disc (Total)\": get_fmt(\"optic_disc_attention\"),\n",
    "        \"Optic disc (Temporal)\": get_fmt(\"optic_disc_attention_temporal\"),\n",
    "        \"Optic disc (Nasal)\":    get_fmt(\"optic_disc_attention_nasal\"),\n",
    "        \"Optic disc (Superior)\": get_fmt(\"optic_disc_attention_superior\"),\n",
    "        \"Optic disc (Inferior)\": get_fmt(\"optic_disc_attention_inferior\"),\n",
    "        \"_sort_key\": desc,  # stable ordering\n",
    "    }\n",
    "    return row\n",
    "\n",
    "def build_table(kind: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for p in glob_summaries(kind):\n",
    "        try:\n",
    "            rows.append(one_row_from_summary(p))\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to read {p}: {e}\")\n",
    "    cols = [\n",
    "        \"Model\",\"Finetuning Method\",\"Non-(vessel or optic disc)\",\n",
    "        \"Artery\",\"Vein\",\"Vessel (Artery + Vein)\",\n",
    "        \"Optic disc (Total)\",\n",
    "        \"Optic disc (Temporal)\",\"Optic disc (Nasal)\",\"Optic disc (Superior)\",\"Optic disc (Inferior)\"\n",
    "    ]\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "    return (pd.DataFrame(rows)\n",
    "              .sort_values(\"_sort_key\")\n",
    "              .drop(columns=[\"_sort_key\"]))[cols]\n",
    "\n",
    "# === Build tables ===\n",
    "detection_df  = build_table(\"TEST\")    # Dementia detection\n",
    "prediction_df = build_table(\"FUTURE\")  # Dementia prediction\n",
    "\n",
    "try:\n",
    "    from caas_jupyter_tools import display_dataframe_to_user\n",
    "    display_dataframe_to_user(\"Dementia detection — Relative ratio table\", detection_df)\n",
    "    display_dataframe_to_user(\"Dementia prediction — Relative ratio table\", prediction_df)\n",
    "except Exception:\n",
    "    pass \n",
    "\n",
    "print(\"\\n=== Dementia detection (Relative ratio, 95% CI) ===\")\n",
    "print(detection_df.to_string(index=False))\n",
    "print(\"\\n=== Dementia prediction (Relative ratio, 95% CI) ===\")\n",
    "print(prediction_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e919833b-1916-445c-a6c3-ec74509f54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_df.to_csv('./summary_tables/ATTN_summary_detection.csv')\n",
    "prediction_df.to_csv('./summary_tables/ATTN_summary_prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b7a6bc-f465-4446-a68d-0628c1da86b6",
   "metadata": {},
   "source": [
    "## colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff984766-0e51-469f-83be-59a6c8eb05d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Colorbar only (same as 'jet' colormap used in saliency)\n",
    "# --------------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(2.0, 10.5))\n",
    "\n",
    "# 0~1 범위의 더미 데이터 (값 없이 색상만 표시)\n",
    "gradient = np.linspace(0, 1, 256).reshape(-1, 1)\n",
    "#im = ax.imshow(gradient, aspect='auto', cmap='jet', origin='lower')\n",
    "\n",
    "# 축 숨기기\n",
    "ax.set_axis_off()\n",
    "\n",
    "# 세로 colorbar 추가\n",
    "cbar = plt.colorbar(im, ax=ax, fraction=0.5, pad=2)\n",
    "#cbar.set_label(\"Saliency intensity\", fontsize=12)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "cbar.set_ticks([])\n",
    "cbar.outline.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31c3a9-21e4-43c0-9c09-0d721a65f65d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automorph",
   "language": "python",
   "name": "automorph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
